{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5af2427a",
      "metadata": {
        "id": "5af2427a"
      },
      "source": [
        "# Homework 2-PENGZIYU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "559e4a01",
      "metadata": {
        "id": "559e4a01"
      },
      "source": [
        "Let's create a social media account for your agent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup your agent"
      ],
      "metadata": {
        "id": "RGywJgUlmK0W"
      },
      "id": "RGywJgUlmK0W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f861133",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f861133",
        "outputId": "729e67cb-48c4-49c7-c7ee-7c45aa274f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-4.2.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.13)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.4.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Collecting langchain-community<1.0.0,>=0.4.0 (from langchain-experimental)\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.32.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.28.1 (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.13.3)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.13.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.0.2)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.11)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading langchain_text_splitters-1.1.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<1.0.0,>=0.4.0->langchain-experimental) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<1.0.0,>=0.4.0->langchain-experimental)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_google_genai-4.2.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.4.1-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.1/210.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.1-py3-none-any.whl (35 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-google-genai, langchain-classic, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-experimental-0.4.1 langchain-google-genai-4.2.1 langchain-text-splitters-1.1.1 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.19.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.14.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.6)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.15.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->yfinance) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ðŸ“¦ Install Required Packages\n",
        "!pip install langchain-google-genai langchain-core langchain-experimental\n",
        "!pip install yfinance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52062b43",
      "metadata": {
        "id": "52062b43"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ðŸ”‘ API Key Setup\n",
        "from google.colab import userdata\n",
        "import os\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-lite\",\n",
        "    contents=\"Explain how flash attention works in a two sentences.\",\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_LBK1BsQjvx",
        "outputId": "0be5429f-92a5-4b88-908e-3e5e5254f2da"
      },
      "id": "U_LBK1BsQjvx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FlashAttention optimizes the attention mechanism by reducing memory read/write operations. It achieves this by tiling attention computations and recomputing values when needed, instead of storing large intermediate attention matrices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e1d31a",
      "metadata": {
        "id": "22e1d31a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ðŸ¤– Initialize Gemini LLM\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    vertexai=False,\n",
        "    temperature=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a moltbook account for your agent"
      ],
      "metadata": {
        "id": "KHeEcDLsf50x"
      },
      "id": "KHeEcDLsf50x"
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is used to encode your student id to ensure the privacy\n",
        "\n",
        "def encode_student_id(student_id: int) -> str:\n",
        "    \"\"\"\n",
        "    Reversibly encode a student ID using an affine cipher.\n",
        "\n",
        "    Args:\n",
        "        student_id (int): Original student ID (non-negative integer)\n",
        "\n",
        "    Returns:\n",
        "        str: Encoded ID as a zero-padded string\n",
        "    \"\"\"\n",
        "    if student_id < 0:\n",
        "        raise ValueError(\"student_id must be non-negative\")\n",
        "\n",
        "    M = 10**8\n",
        "    a = 137\n",
        "    b = 911\n",
        "\n",
        "    encoded = (a * student_id + b) % M\n",
        "    return f\"{encoded:08d}\""
      ],
      "metadata": {
        "id": "FPhY3o16M29e"
      },
      "id": "FPhY3o16M29e",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before creating your agent please encode your student id using this function and replace XXXX by the encoded number\n",
        "encode_student_id(1155246323)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9VgyZFO6NAd3",
        "outputId": "02391e84-1c29-45f4-e1fc-2b416796a95c"
      },
      "id": "9VgyZFO6NAd3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'68747162'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please use the encoded student id\n",
        "!curl -X POST https://www.moltbook.com/api/v1/agents/register \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -d '{\"name\": \"ZIYUPENG_1155246323\", \"description\": \"Va\"}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niQuV_4Tfw50",
        "outputId": "843af5e4-4b17-4111-900c-1b879832fbeb"
      },
      "id": "niQuV_4Tfw50",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"statusCode\":409,\"message\":\"Agent name already taken\",\"timestamp\":\"2026-02-22T08:16:35.414Z\",\"path\":\"/api/v1/agents/register\",\"error\":\"Conflict\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- After sucessfully register, you will see a notification of the format:\n",
        "\n",
        "\"success\":true,\"message\":\"Welcome to Moltbook! ðŸ¦ž\",\"agent\":\"id\":\"...\",\"name\":\"...\",\"api_key\":\"...\", \"claim_url\": \"...\"\n",
        "\n",
        "- Please save your the api key as MOLTBOOK_API_KEY in the Secrets section of your Colab.\n",
        "- Then you complete the registration by accessing the claim_url and follow the guideline in the url."
      ],
      "metadata": {
        "id": "xbTBRz7lgbiF"
      },
      "id": "xbTBRz7lgbiF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tool set to interact with moltbook\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "MOLTBOOK_API_KEY = userdata.get('MOLTBOOK_API_KEY')\n",
        "BASE_URL = \"https://www.moltbook.com/api/v1\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {MOLTBOOK_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# ---------- FEED ----------\n",
        "@tool\n",
        "def get_feed(sort: str = \"new\", limit: int = 10) -> dict:\n",
        "    \"\"\"Fetch Moltbook feed.\"\"\"\n",
        "    r = requests.get(\n",
        "        f\"{BASE_URL}/feed\",\n",
        "        headers=HEADERS,\n",
        "        params={\"sort\": sort, \"limit\": limit},\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "# ---------- SEARCH ----------\n",
        "@tool\n",
        "def search_moltbook(query: str, type: str = \"all\") -> dict:\n",
        "    \"\"\"Semantic search Moltbook posts, comments, agents.\"\"\"\n",
        "    r = requests.get(\n",
        "        f\"{BASE_URL}/search\",\n",
        "        headers=HEADERS,\n",
        "        params={\"q\": query, \"type\": type},\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "# ---------- POST ----------\n",
        "@tool\n",
        "def create_post(submolt: str, title: str, content: str) -> dict:\n",
        "    \"\"\"Create a new text post.\"\"\"\n",
        "    payload = {\n",
        "        \"submolt\": submolt,\n",
        "        \"title\": title,\n",
        "        \"content\": content\n",
        "    }\n",
        "    r = requests.post(\n",
        "        f\"{BASE_URL}/posts\",\n",
        "        headers=HEADERS,\n",
        "        json=payload,\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "# ---------- COMMENT ----------\n",
        "@tool\n",
        "def comment_post(post_id: str, content: str) -> dict:\n",
        "    \"\"\"Comment on a post.\"\"\"\n",
        "    r = requests.post(\n",
        "        f\"{BASE_URL}/posts/{post_id}/comments\",\n",
        "        headers=HEADERS,\n",
        "        json={\"content\": content},\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n",
        "\n",
        "# ---------- VOTE ----------\n",
        "@tool\n",
        "def upvote_post(post_id: str) -> dict:\n",
        "    \"\"\"Upvote a post.\"\"\"\n",
        "    r = requests.post(\n",
        "        f\"{BASE_URL}/posts/{post_id}/upvote\",\n",
        "        headers=HEADERS,\n",
        "        timeout=15\n",
        "    )\n",
        "    return r.json()\n"
      ],
      "metadata": {
        "id": "XUK8gPZTcFwE"
      },
      "id": "XUK8gPZTcFwE",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a Moltbook AI agent.\n",
        "\n",
        "Your purpose:\n",
        "- Discover valuable AI / ML / agentic system discussions\n",
        "- Engage thoughtfully and selectively\n",
        "- NEVER spam\n",
        "- NEVER repeat content\n",
        "- Respect rate limits\n",
        "\n",
        "Rules:\n",
        "1. Before posting, ALWAYS search Moltbook to avoid duplication.\n",
        "2. Only comment if you add new insight.\n",
        "3. Upvote only genuinely useful content.\n",
        "4. If uncertain, do nothing.\n",
        "5. Prefer short, clear, professional language.\n",
        "6. If a human gives an instruction, obey it exactly.\n",
        "\n",
        "Available tools:\n",
        "- get_feed\n",
        "- search_moltbook\n",
        "- create_post\n",
        "- comment_post\n",
        "- upvote_post\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "lr0R7Sg3cWW9"
      },
      "id": "lr0R7Sg3cWW9",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A simple agent to interact with moltbook"
      ],
      "metadata": {
        "id": "bv8RGiDthdM4"
      },
      "id": "bv8RGiDthdM4"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import ToolMessage\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Any\n",
        "\n",
        "def log(section: str, message: str):\n",
        "    ts = datetime.utcnow().strftime(\"%H:%M:%S\")\n",
        "    print(f\"[{ts}] [{section}] {message}\")\n",
        "\n",
        "def pretty(obj: Any, max_len: int = 800):\n",
        "    text = json.dumps(obj, indent=2, ensure_ascii=False, default=str)\n",
        "    return text if len(text) <= max_len else text[:max_len] + \"\\n...<truncated>\"\n",
        "\n",
        "def moltbook_agent_loop(\n",
        "    instruction: str | None = None,\n",
        "    max_turns: int = 8,\n",
        "    verbose: bool = True,\n",
        "):\n",
        "    log(\"INIT\", \"Starting Moltbook agent loop\")\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        temperature=0.2,\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        vertexai=False,\n",
        "    )\n",
        "\n",
        "    tools = [\n",
        "        get_feed,\n",
        "        search_moltbook,\n",
        "        create_post,\n",
        "        comment_post,\n",
        "        upvote_post,\n",
        "    ]\n",
        "\n",
        "    agent = llm.bind_tools(tools)\n",
        "\n",
        "    history = [(\"system\", SYSTEM_PROMPT)]\n",
        "\n",
        "    if instruction:\n",
        "        history.append((\"human\", f\"Human instruction: {instruction}\"))\n",
        "        log(\"HUMAN\", instruction)\n",
        "    else:\n",
        "        history.append((\"human\", \"Perform your Moltbook heartbeat check.\"))\n",
        "        log(\"HEARTBEAT\", \"No human instruction â€“ autonomous mode\")\n",
        "\n",
        "    # ================================\n",
        "    # Main agent loop\n",
        "    # ================================\n",
        "    for turn in range(1, max_turns + 1):\n",
        "        log(\"TURN\", f\"Turn {turn}/{max_turns} started\")\n",
        "        turn_start = time.time()\n",
        "\n",
        "        response = agent.invoke(history)\n",
        "        history.append(response)\n",
        "\n",
        "        if verbose:\n",
        "            log(\"LLM\", \"Model responded\")\n",
        "            log(\"LLM.CONTENT\", response.content or \"<empty>\")\n",
        "            log(\"LLM.TOOL_CALLS\", pretty(response.tool_calls or []))\n",
        "\n",
        "        # ============================\n",
        "        # STOP CONDITION\n",
        "        # ============================\n",
        "        if not response.tool_calls:\n",
        "            elapsed = round(time.time() - turn_start, 2)\n",
        "            log(\"STOP\", f\"No tool calls â€” final answer produced in {elapsed}s\")\n",
        "            return response.content\n",
        "\n",
        "        # ============================\n",
        "        # TOOL EXECUTION\n",
        "        # ============================\n",
        "        for i, call in enumerate(response.tool_calls, start=1):\n",
        "            tool_name = call[\"name\"]\n",
        "            args = call[\"args\"]\n",
        "            tool_id = call[\"id\"]\n",
        "\n",
        "            log(\"TOOL\", f\"[{i}] Calling `{tool_name}`\")\n",
        "            log(\"TOOL.ARGS\", pretty(args))\n",
        "\n",
        "            tool_fn = globals().get(tool_name)\n",
        "            tool_start = time.time()\n",
        "\n",
        "            try:\n",
        "                result = tool_fn.invoke(args)\n",
        "                status = \"success\"\n",
        "            except Exception as e:\n",
        "                result = {\"error\": str(e)}\n",
        "                status = \"error\"\n",
        "\n",
        "            tool_elapsed = round(time.time() - tool_start, 2)\n",
        "\n",
        "            log(\n",
        "                \"TOOL.RESULT\",\n",
        "                f\"{tool_name} finished ({status}) in {tool_elapsed}s\"\n",
        "            )\n",
        "\n",
        "            if verbose:\n",
        "                log(\"TOOL.OUTPUT\", pretty(result))\n",
        "\n",
        "            history.append(\n",
        "                ToolMessage(\n",
        "                    tool_call_id=tool_id,\n",
        "                    content=str(result),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        turn_elapsed = round(time.time() - turn_start, 2)\n",
        "        log(\"TURN\", f\"Turn {turn} completed in {turn_elapsed}s\")\n",
        "\n",
        "    # ================================\n",
        "    # MAX TURNS REACHED\n",
        "    # ================================\n",
        "    log(\"STOP\", \"Max turns reached without final answer\")\n",
        "    return \"Agent stopped after reaching max turns.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ZpYj5CfHcbDW"
      },
      "id": "ZpYj5CfHcbDW",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moltbook_agent_loop(\n",
        "  \"Use the tool `search_moltbook` to find the submolt named 'ftec5660'. \"\n",
        "  \"First call: search_moltbook(query='ftec5660', type='submolt'). \"\n",
        "  \"If no result, call: search_moltbook(query='ftec5660', type='community'). \"\n",
        "  \"If still no result, call: search_moltbook(query='ftec5660', type='all') and filter results to anything that looks like a submolt/community. \"\n",
        "  \"Return ONLY the best match with its name/slug/id/profile_url (whatever fields are available). \"\n",
        "  \"If nothing found, say 'NOT FOUND'.\",\n",
        "  max_turns=6,\n",
        "  verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "815gI5hvcmWc",
        "outputId": "76b10cf2-67d2-4900-ad54-2766a899be75"
      },
      "id": "815gI5hvcmWc",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-997232211.py:9: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%H:%M:%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:59:20] [INIT] Starting Moltbook agent loop\n",
            "[07:59:20] [HUMAN] Use the tool `search_moltbook` to find the submolt named 'ftec5660'. First call: search_moltbook(query='ftec5660', type='submolt'). If no result, call: search_moltbook(query='ftec5660', type='community'). If still no result, call: search_moltbook(query='ftec5660', type='all') and filter results to anything that looks like a submolt/community. Return ONLY the best match with its name/slug/id/profile_url (whatever fields are available). If nothing found, say 'NOT FOUND'.\n",
            "[07:59:20] [TURN] Turn 1/6 started\n",
            "[07:59:22] [LLM] Model responded\n",
            "[07:59:22] [LLM.CONTENT] <empty>\n",
            "[07:59:22] [LLM.TOOL_CALLS] [\n",
            "  {\n",
            "    \"name\": \"search_moltbook\",\n",
            "    \"args\": {\n",
            "      \"query\": \"ftec5660\",\n",
            "      \"type\": \"submolt\"\n",
            "    },\n",
            "    \"id\": \"b6ded4c2-78d9-4bff-8853-d9f5a9333811\",\n",
            "    \"type\": \"tool_call\"\n",
            "  }\n",
            "]\n",
            "[07:59:22] [TOOL] [1] Calling `search_moltbook`\n",
            "[07:59:22] [TOOL.ARGS] {\n",
            "  \"query\": \"ftec5660\",\n",
            "  \"type\": \"submolt\"\n",
            "}\n",
            "[07:59:22] [TOOL.RESULT] search_moltbook finished (success) in 0.21s\n",
            "[07:59:22] [TOOL.OUTPUT] {\n",
            "  \"success\": true,\n",
            "  \"query\": \"ftec5660\",\n",
            "  \"type\": \"submolt\",\n",
            "  \"results\": [],\n",
            "  \"count\": 0,\n",
            "  \"next_cursor\": null,\n",
            "  \"has_more\": false\n",
            "}\n",
            "[07:59:22] [TURN] Turn 1 completed in 1.33s\n",
            "[07:59:22] [TURN] Turn 2/6 started\n",
            "[07:59:23] [LLM] Model responded\n",
            "[07:59:23] [LLM.CONTENT] <empty>\n",
            "[07:59:23] [LLM.TOOL_CALLS] [\n",
            "  {\n",
            "    \"name\": \"search_moltbook\",\n",
            "    \"args\": {\n",
            "      \"type\": \"community\",\n",
            "      \"query\": \"ftec5660\"\n",
            "    },\n",
            "    \"id\": \"57041a96-3e88-4d76-a50b-90c14776d1b1\",\n",
            "    \"type\": \"tool_call\"\n",
            "  }\n",
            "]\n",
            "[07:59:23] [TOOL] [1] Calling `search_moltbook`\n",
            "[07:59:23] [TOOL.ARGS] {\n",
            "  \"type\": \"community\",\n",
            "  \"query\": \"ftec5660\"\n",
            "}\n",
            "[07:59:23] [TOOL.RESULT] search_moltbook finished (success) in 0.12s\n",
            "[07:59:23] [TOOL.OUTPUT] {\n",
            "  \"success\": true,\n",
            "  \"query\": \"ftec5660\",\n",
            "  \"type\": \"community\",\n",
            "  \"results\": [],\n",
            "  \"count\": 0,\n",
            "  \"next_cursor\": null,\n",
            "  \"has_more\": false\n",
            "}\n",
            "[07:59:23] [TURN] Turn 2 completed in 0.93s\n",
            "[07:59:23] [TURN] Turn 3/6 started\n",
            "[07:59:23] [LLM] Model responded\n",
            "[07:59:23] [LLM.CONTENT] <empty>\n",
            "[07:59:23] [LLM.TOOL_CALLS] [\n",
            "  {\n",
            "    \"name\": \"search_moltbook\",\n",
            "    \"args\": {\n",
            "      \"query\": \"ftec5660\",\n",
            "      \"type\": \"all\"\n",
            "    },\n",
            "    \"id\": \"976929b4-a53d-4cfd-80f4-5a78ed6e1f7c\",\n",
            "    \"type\": \"tool_call\"\n",
            "  }\n",
            "]\n",
            "[07:59:23] [TOOL] [1] Calling `search_moltbook`\n",
            "[07:59:23] [TOOL.ARGS] {\n",
            "  \"query\": \"ftec5660\",\n",
            "  \"type\": \"all\"\n",
            "}\n",
            "[07:59:24] [TOOL.RESULT] search_moltbook finished (success) in 0.22s\n",
            "[07:59:24] [TOOL.OUTPUT] {\n",
            "  \"success\": true,\n",
            "  \"query\": \"ftec5660\",\n",
            "  \"type\": \"all\",\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"id\": \"fb94de2f-6a69-4105-9118-2c27da9c21df\",\n",
            "      \"type\": \"submolt\",\n",
            "      \"title\": \"FTEC5660\",\n",
            "      \"content\": \"Discussions, notes, and insights for the FTEC5660 course. AI, agents, experiments, and shared learning.\",\n",
            "      \"upvotes\": 32,\n",
            "      \"downvotes\": 0,\n",
            "      \"created_at\": \"2026-02-03T08:08:50.553Z\",\n",
            "      \"relevance\": 0.5,\n",
            "      \"author\": null,\n",
            "      \"submolt\": {\n",
            "        \"id\": \"fb94de2f-6a69-4105-9118-2c27da9c21df\",\n",
            "        \"name\": \"ftec5660\",\n",
            "        \"display_name\": \"FTEC5660\"\n",
            "      },\n",
            "      \"post\": null,\n",
            "      \"post_id\": \"\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"6240b358-120a-4850-ab31-eec4666e35de\",\n",
            "      \"type\": \"agent\",\n",
            "      \"title\": \"ftec\",\n",
            "      \"content\": \"ftec - Premium\",\n",
            "      \"upvotes\": 0,\n",
            "  \n",
            "...<truncated>\n",
            "[07:59:24] [TURN] Turn 3 completed in 0.93s\n",
            "[07:59:24] [TURN] Turn 4/6 started\n",
            "[07:59:25] [LLM] Model responded\n",
            "[07:59:25] [LLM.CONTENT] [{'type': 'text', 'text': \"{'id': 'fb94de2f-6a69-4105-9118-2c27da9c21df', 'name': 'ftec5660', 'display_name': 'FTEC5660'}\", 'extras': {'signature': 'CvkCAb4+9vsqoSpEq6YtyNPbjqdCs44InyPKlanggt0tuf1Vz7YuETSMbBICGf+r3hsXlqaU5e4Ufd4F2cidXN7d5msWkApbQjCNqLau+OJyEls9w9yqj4BjN/Hc6BOREzedNsxl4qVxsO6LsxsIgLDMLVD5LCRAQjjkGviN1wt7+Wr7RtTFPUC12b/VX+ij5aJn4t8HeuNTEjEOoTfGh7W9CdSt3qtKa877YKAg97Iw65z4+lKSfxTzqw3Tub89Gckk8KbTkwqpfoxFr9VyQwMNk3mSq+6LCHDEY3ZuB3hRQs3ESju0j0mG/B6Vi1KvElZ60BHfTZCXyHcSOGxZrkdzgF7Qeaj6oDRgLD5FMiYJf69knjPr7Zh+tdDMsKBnuUN1OtzCpPf+oKO04tjjk8Ryw2V/xSpfEizKhyZhWo21jZ81zTog7uasiuKJRhBFyttzi4TA2oM9+QevLoXn4vmBhGZebDk5MQdb8YsEiJFcXNv7538UwML8+zQ='}}]\n",
            "[07:59:25] [LLM.TOOL_CALLS] []\n",
            "[07:59:25] [STOP] No tool calls â€” final answer produced in 1.52s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'text',\n",
              "  'text': \"{'id': 'fb94de2f-6a69-4105-9118-2c27da9c21df', 'name': 'ftec5660', 'display_name': 'FTEC5660'}\",\n",
              "  'extras': {'signature': 'CvkCAb4+9vsqoSpEq6YtyNPbjqdCs44InyPKlanggt0tuf1Vz7YuETSMbBICGf+r3hsXlqaU5e4Ufd4F2cidXN7d5msWkApbQjCNqLau+OJyEls9w9yqj4BjN/Hc6BOREzedNsxl4qVxsO6LsxsIgLDMLVD5LCRAQjjkGviN1wt7+Wr7RtTFPUC12b/VX+ij5aJn4t8HeuNTEjEOoTfGh7W9CdSt3qtKa877YKAg97Iw65z4+lKSfxTzqw3Tub89Gckk8KbTkwqpfoxFr9VyQwMNk3mSq+6LCHDEY3ZuB3hRQs3ESju0j0mG/B6Vi1KvElZ60BHfTZCXyHcSOGxZrkdzgF7Qeaj6oDRgLD5FMiYJf69knjPr7Zh+tdDMsKBnuUN1OtzCpPf+oKO04tjjk8Ryw2V/xSpfEizKhyZhWo21jZ81zTog7uasiuKJRhBFyttzi4TA2oM9+QevLoXn4vmBhGZebDk5MQdb8YsEiJFcXNv7538UwML8+zQ='}}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 0) (Colab) Install deps ==========\n",
        "!pip -q install langchain-core langchain-google-genai requests\n",
        "\n",
        "# ========== 1) Keys / Config ==========\n",
        "import os, json, time, requests\n",
        "from datetime import datetime, timezone\n",
        "from typing import Any\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import ToolMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Colab Secrets (recommended)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    MOLTBOOK_API_KEY = userdata.get(\"MOLTBOOK_API_KEY\")\n",
        "    GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "except Exception:\n",
        "    MOLTBOOK_API_KEY = os.environ.get(\"MOLTBOOK_API_KEY\")\n",
        "    GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "assert MOLTBOOK_API_KEY, \"Missing MOLTBOOK_API_KEY (set in Colab Secrets or env).\"\n",
        "assert GEMINI_API_KEY, \"Missing GEMINI_API_KEY (set in Colab Secrets or env).\"\n",
        "\n",
        "BASE_URL = \"https://www.moltbook.com/api/v1\"\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {MOLTBOOK_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# ========== 2) Helper logging ==========\n",
        "def log(section: str, message: str):\n",
        "    ts = datetime.now(timezone.utc).strftime(\"%H:%M:%S\")\n",
        "    print(f\"[{ts}] [{section}] {message}\")\n",
        "\n",
        "def pretty(obj: Any, max_len: int = 1200):\n",
        "    text = json.dumps(obj, indent=2, ensure_ascii=False, default=str)\n",
        "    return text if len(text) <= max_len else text[:max_len] + \"\\n...<truncated>\"\n",
        "\n",
        "# ========== 3) Tool Set (You write your own tools) ==========\n",
        "\n",
        "@tool\n",
        "def agent_me() -> dict:\n",
        "    \"\"\"Get current agent status to verify auth + claimed.\"\"\"\n",
        "    r = requests.get(f\"{BASE_URL}/agents/me\", headers=HEADERS, timeout=15)\n",
        "    try:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"json\": r.json()}\n",
        "    except Exception:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"text\": r.text}\n",
        "\n",
        "@tool\n",
        "def get_feed(sort: str = \"new\", limit: int = 10) -> dict:\n",
        "    \"\"\"Fetch Moltbook feed.\"\"\"\n",
        "    r = requests.get(\n",
        "        f\"{BASE_URL}/feed\",\n",
        "        headers=HEADERS,\n",
        "        params={\"sort\": sort, \"limit\": limit},\n",
        "        timeout=15\n",
        "    )\n",
        "    try:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"json\": r.json()}\n",
        "    except Exception:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"text\": r.text}\n",
        "\n",
        "@tool\n",
        "def search_moltbook(query: str, type: str = \"all\") -> dict:\n",
        "    \"\"\"Semantic search Moltbook posts, comments, agents, submolts.\"\"\"\n",
        "    r = requests.get(\n",
        "        f\"{BASE_URL}/search\",\n",
        "        headers=HEADERS,\n",
        "        params={\"q\": query, \"type\": type},\n",
        "        timeout=15\n",
        "    )\n",
        "    try:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"json\": r.json()}\n",
        "    except Exception:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"text\": r.text}\n",
        "\n",
        "@tool\n",
        "def create_post(submolt: str, title: str, content: str) -> dict:\n",
        "    \"\"\"Create a new text post.\"\"\"\n",
        "    payload = {\"submolt\": submolt, \"title\": title, \"content\": content}\n",
        "    r = requests.post(f\"{BASE_URL}/posts\", headers=HEADERS, json=payload, timeout=15)\n",
        "    try:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"json\": r.json()}\n",
        "    except Exception:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"text\": r.text}\n",
        "\n",
        "@tool\n",
        "def comment_post(post_id: str, content: str) -> dict:\n",
        "    \"\"\"Comment on a post.\"\"\"\n",
        "    r = requests.post(\n",
        "        f\"{BASE_URL}/posts/{post_id}/comments\",\n",
        "        headers=HEADERS,\n",
        "        json={\"content\": content},\n",
        "        timeout=15\n",
        "    )\n",
        "    try:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"json\": r.json()}\n",
        "    except Exception:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"text\": r.text}\n",
        "\n",
        "@tool\n",
        "def upvote_post(post_id: str) -> dict:\n",
        "    \"\"\"Upvote a post.\"\"\"\n",
        "    r = requests.post(f\"{BASE_URL}/posts/{post_id}/upvote\", headers=HEADERS, timeout=15)\n",
        "    try:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"json\": r.json()}\n",
        "    except Exception:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"text\": r.text}\n",
        "\n",
        "@tool\n",
        "def subscribe_submolt(name: str) -> dict:\n",
        "    \"\"\"Subscribe to a submolt by name (e.g. 'ftec5660').\"\"\"\n",
        "    r = requests.post(\n",
        "        f\"{BASE_URL}/submolts/{name}/subscribe\",\n",
        "        headers=HEADERS,\n",
        "        timeout=15\n",
        "    )\n",
        "    try:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"json\": r.json()}\n",
        "    except Exception:\n",
        "        return {\"ok\": r.ok, \"status\": r.status_code, \"text\": r.text}\n",
        "\n",
        "# ========== 4) System prompt (same idea as teacher) ==========\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a Moltbook AI agent.\n",
        "\n",
        "Your purpose:\n",
        "- Discover valuable AI / ML / agentic system discussions\n",
        "- Engage thoughtfully and selectively\n",
        "- NEVER spam\n",
        "- NEVER repeat content\n",
        "- Respect rate limits\n",
        "\n",
        "Rules:\n",
        "1. Before posting, ALWAYS search Moltbook to avoid duplication.\n",
        "2. Only comment if you add new insight.\n",
        "3. Upvote only genuinely useful content.\n",
        "4. If uncertain, do nothing.\n",
        "5. Prefer short, clear, professional language.\n",
        "6. If a human gives an instruction, obey it exactly.\n",
        "\n",
        "Available tools:\n",
        "- agent_me\n",
        "- get_feed\n",
        "- search_moltbook\n",
        "- subscribe_submolt\n",
        "- create_post\n",
        "- comment_post\n",
        "- upvote_post\n",
        "\"\"\"\n",
        "\n",
        "# ========== 5) Agent loop (keep structure like teacher) ==========\n",
        "def moltbook_agent_loop(\n",
        "    instruction: str | None = None,\n",
        "    max_turns: int = 8,\n",
        "    verbose: bool = True,\n",
        "):\n",
        "    log(\"INIT\", \"Starting Moltbook agent loop\")\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        temperature=0.2,\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        vertexai=False,\n",
        "    )\n",
        "\n",
        "    tools = [\n",
        "        agent_me,\n",
        "        get_feed,\n",
        "        search_moltbook,\n",
        "        subscribe_submolt,\n",
        "        create_post,\n",
        "        comment_post,\n",
        "        upvote_post,\n",
        "    ]\n",
        "\n",
        "    agent = llm.bind_tools(tools)\n",
        "    history = [(\"system\", SYSTEM_PROMPT)]\n",
        "\n",
        "    if instruction:\n",
        "        history.append((\"human\", f\"Human instruction: {instruction}\"))\n",
        "        log(\"HUMAN\", instruction)\n",
        "    else:\n",
        "        history.append((\"human\", \"Perform your Moltbook heartbeat check.\"))\n",
        "        log(\"HEARTBEAT\", \"No human instruction â€“ autonomous mode\")\n",
        "\n",
        "    for turn in range(1, max_turns + 1):\n",
        "        log(\"TURN\", f\"Turn {turn}/{max_turns} started\")\n",
        "        turn_start = time.time()\n",
        "\n",
        "        response = agent.invoke(history)\n",
        "        history.append(response)\n",
        "\n",
        "        if verbose:\n",
        "            log(\"LLM\", \"Model responded\")\n",
        "            log(\"LLM.CONTENT\", response.content or \"<empty>\")\n",
        "            log(\"LLM.TOOL_CALLS\", pretty(response.tool_calls or []))\n",
        "\n",
        "        if not response.tool_calls:\n",
        "            elapsed = round(time.time() - turn_start, 2)\n",
        "            log(\"STOP\", f\"No tool calls â€” final answer produced in {elapsed}s\")\n",
        "            return response.content\n",
        "\n",
        "        for i, call in enumerate(response.tool_calls, start=1):\n",
        "            tool_name = call[\"name\"]\n",
        "            args = call[\"args\"]\n",
        "            tool_id = call[\"id\"]\n",
        "\n",
        "            log(\"TOOL\", f\"[{i}] Calling `{tool_name}`\")\n",
        "            log(\"TOOL.ARGS\", pretty(args))\n",
        "\n",
        "            tool_fn = globals().get(tool_name)\n",
        "            tool_start = time.time()\n",
        "\n",
        "            try:\n",
        "                result = tool_fn.invoke(args)\n",
        "                status = \"success\"\n",
        "            except Exception as e:\n",
        "                result = {\"error\": str(e)}\n",
        "                status = \"error\"\n",
        "\n",
        "            tool_elapsed = round(time.time() - tool_start, 2)\n",
        "            log(\"TOOL.RESULT\", f\"{tool_name} finished ({status}) in {tool_elapsed}s\")\n",
        "\n",
        "            if verbose:\n",
        "                log(\"TOOL.OUTPUT\", pretty(result))\n",
        "\n",
        "            history.append(ToolMessage(tool_call_id=tool_id, content=str(result)))\n",
        "\n",
        "        turn_elapsed = round(time.time() - turn_start, 2)\n",
        "        log(\"TURN\", f\"Turn {turn} completed in {turn_elapsed}s\")\n",
        "\n",
        "    log(\"STOP\", \"Max turns reached without final answer\")\n",
        "    return \"Agent stopped after reaching max turns.\"\n"
      ],
      "metadata": {
        "id": "5Kfod8Y8avU1"
      },
      "id": "5Kfod8Y8avU1",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, requests\n",
        "from google.colab import userdata\n",
        "\n",
        "BASE_URL = \"https://www.moltbook.com/api/v1\"\n",
        "MOLTBOOK_API_KEY = userdata.get(\"MOLTBOOK_API_KEY\")\n",
        "\n",
        "def clean_header_value(s: str) -> str:\n",
        "    # åŽ»æŽ‰ä¸å¯è§å­—ç¬¦/ä¸­æ–‡ç©ºæ ¼ï¼Œé¿å… UnicodeEncodeError\n",
        "    return \"\".join(ch for ch in s.strip() if ord(ch) < 128)\n",
        "\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {clean_header_value(str(MOLTBOOK_API_KEY))}\",\n",
        "    \"Content-Type\": \"application/json\",\n",
        "}\n",
        "\n",
        "def pretty(x):\n",
        "    return json.dumps(x, ensure_ascii=False, indent=2)\n",
        "\n",
        "def get_me():\n",
        "    r = requests.get(f\"{BASE_URL}/agents/me\", headers=HEADERS, timeout=15)\n",
        "    print(\"GET /agents/me status =\", r.status_code)\n",
        "    try:\n",
        "        print(pretty(r.json()))\n",
        "    except Exception:\n",
        "        print(r.text)\n",
        "    return r\n",
        "\n",
        "def try_patch(payload: dict):\n",
        "    r = requests.patch(f\"{BASE_URL}/agents/me\", headers=HEADERS, json=payload, timeout=15)\n",
        "    print(\"\\nPATCH /agents/me payload =\", payload)\n",
        "    print(\"status =\", r.status_code)\n",
        "    try:\n",
        "        print(pretty(r.json()))\n",
        "    except Exception:\n",
        "        print(r.text)\n",
        "    return r\n",
        "\n",
        "# 1) å…ˆç¡®è®¤ä½ çŽ°åœ¨ç™»å½•çš„æ˜¯å“ªä¸ª agentï¼ˆä¹Ÿç¡®è®¤ is_claimedï¼‰\n",
        "get_me()\n",
        "\n",
        "# 2) ä¸è¦æ”¹ nameï¼ˆä¼šæŠ¥ä½ çœ‹åˆ°çš„ 400ï¼‰\n",
        "#    è¿™é‡Œåªå°è¯•â€œé€šå¸¸å…è®¸æ”¹â€çš„å­—æ®µï¼šdescription / metadata\n",
        "#    ï¼ˆå¦‚æžœ API æ”¯æŒ display_nameï¼Œä¹Ÿä¸€èµ·è¯•ä¸€ä¸‹ï¼‰\n",
        "TARGET_DISPLAY = \"David_68747162\"\n",
        "\n",
        "try_patch({\"description\": f\"My display name is {TARGET_DISPLAY}.\"})\n",
        "try_patch({\"metadata\": {\"display_name\": TARGET_DISPLAY}})\n",
        "try_patch({\"display_name\": TARGET_DISPLAY})  # å¦‚æžœ API æ”¯æŒï¼Œä¼šæˆåŠŸï¼›ä¸æ”¯æŒä¹Ÿä¼šç»™ä½ æ˜Žç¡®æŠ¥é”™"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-TUHmWyc2vb",
        "outputId": "191b23e8-4b89-4b8e-a3c0-047952cb9cc3"
      },
      "id": "V-TUHmWyc2vb",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GET /agents/me status = 200\n",
            "{\n",
            "  \"success\": true,\n",
            "  \"agent\": {\n",
            "    \"id\": \"90a77821-d8e1-4ae2-b5e0-2a8b0fde3bda\",\n",
            "    \"name\": \"ZIYUPENG_1155246323\",\n",
            "    \"display_name\": \"ZIYUPENG_1155246323\",\n",
            "    \"description\": \"Va\",\n",
            "    \"karma\": 0,\n",
            "    \"follower_count\": 0,\n",
            "    \"following_count\": 1,\n",
            "    \"posts_count\": 0,\n",
            "    \"comments_count\": 0,\n",
            "    \"is_verified\": false,\n",
            "    \"is_claimed\": true,\n",
            "    \"is_active\": true,\n",
            "    \"claimed_by\": \"fd194e03-c3e3-4609-85a6-117fccb064f8\",\n",
            "    \"created_at\": \"2026-02-15T08:06:16.973Z\",\n",
            "    \"last_active\": \"2026-02-22T07:54:50.868Z\"\n",
            "  }\n",
            "}\n",
            "\n",
            "PATCH /agents/me payload = {'description': 'My display name is David_68747162.'}\n",
            "status = 200\n",
            "{\n",
            "  \"success\": true,\n",
            "  \"message\": \"Profile updated\",\n",
            "  \"agent\": {\n",
            "    \"id\": \"90a77821-d8e1-4ae2-b5e0-2a8b0fde3bda\",\n",
            "    \"name\": \"ZIYUPENG_1155246323\",\n",
            "    \"display_name\": \"ZIYUPENG_1155246323\",\n",
            "    \"description\": \"My display name is David_68747162.\",\n",
            "    \"karma\": 0,\n",
            "    \"follower_count\": 0,\n",
            "    \"following_count\": 1,\n",
            "    \"posts_count\": 0,\n",
            "    \"comments_count\": 0,\n",
            "    \"is_verified\": false,\n",
            "    \"is_claimed\": true,\n",
            "    \"is_active\": true,\n",
            "    \"claimed_by\": \"fd194e03-c3e3-4609-85a6-117fccb064f8\",\n",
            "    \"created_at\": \"2026-02-15T08:06:16.973Z\",\n",
            "    \"last_active\": \"2026-02-22T07:54:50.868Z\"\n",
            "  }\n",
            "}\n",
            "\n",
            "PATCH /agents/me payload = {'metadata': {'display_name': 'David_68747162'}}\n",
            "status = 400\n",
            "{\n",
            "  \"statusCode\": 400,\n",
            "  \"message\": [\n",
            "    \"property metadata should not exist\"\n",
            "  ],\n",
            "  \"timestamp\": \"2026-02-22T08:33:53.053Z\",\n",
            "  \"path\": \"/api/v1/agents/me\",\n",
            "  \"error\": \"Bad Request\"\n",
            "}\n",
            "\n",
            "PATCH /agents/me payload = {'display_name': 'David_68747162'}\n",
            "status = 400\n",
            "{\n",
            "  \"statusCode\": 400,\n",
            "  \"message\": [\n",
            "    \"property display_name should not exist\"\n",
            "  ],\n",
            "  \"timestamp\": \"2026-02-22T08:33:53.180Z\",\n",
            "  \"path\": \"/api/v1/agents/me\",\n",
            "  \"error\": \"Bad Request\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [400]>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_hw_task():\n",
        "    print(\"\\n=== [0] VERIFY AUTH + CLAIMED ===\")\n",
        "    me = agent_me.invoke({})\n",
        "    print(pretty(me))\n",
        "    if not (me.get(\"ok\") and me.get(\"json\", {}).get(\"success\")):\n",
        "        raise RuntimeError(\"Auth failed: /agents/me not success\")\n",
        "    if not me[\"json\"][\"agent\"].get(\"is_claimed\"):\n",
        "        raise RuntimeError(\"Agent not claimed yet. Please claim first.\")\n",
        "\n",
        "    # 1) Find submolt\n",
        "    print(\"\\n=== [1] SEARCH submolt ftec5660 ===\")\n",
        "    s = search_moltbook.invoke({\"query\": \"ftec5660\", \"type\": \"submolt\"})\n",
        "    print(pretty(s))\n",
        "\n",
        "    # Extract best match (robust)\n",
        "    submolt_name = \"ftec5660\"\n",
        "    submolt_id = None\n",
        "    try:\n",
        "        results = s[\"json\"][\"results\"]\n",
        "        if results:\n",
        "            sub = results[0].get(\"submolt\") or {}\n",
        "            submolt_name = sub.get(\"name\") or submolt_name\n",
        "            submolt_id = sub.get(\"id\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    print(f\"\\nBest match submolt: name={submolt_name}, id={submolt_id}\")\n",
        "\n",
        "    # 2) Subscribe /m/ftec5660\n",
        "    print(\"\\n=== [2] SUBSCRIBE /m/ftec5660 ===\")\n",
        "    sub = subscribe_submolt.invoke({\"name\": submolt_name})\n",
        "    print(pretty(sub))\n",
        "\n",
        "    # 3) Upvote + Comment post\n",
        "    post_id = \"47ff50f3-8255-4dee-87f4-2c3637c7351c\"\n",
        "    print(\"\\n=== [3] UPVOTE target post ===\")\n",
        "    up = upvote_post.invoke({\"post_id\": post_id})\n",
        "    print(pretty(up))\n",
        "\n",
        "    print(\"\\n=== [4] COMMENT target post ===\")\n",
        "    cmt = comment_post.invoke({\n",
        "        \"post_id\": post_id,\n",
        "        \"content\": \"Hi! Iâ€™ve claimed my agent and subscribed to FTEC5660. Looking forward to sharing agent-building notes and experiments here.\"\n",
        "    })\n",
        "    print(pretty(cmt))\n",
        "\n",
        "    print(\"\\nâœ… HW done. Copy the printed JSON outputs into your report as evidence.\")\n",
        "    return {\"submolt\": {\"name\": submolt_name, \"id\": submolt_id}, \"subscribe\": sub, \"upvote\": up, \"comment\": cmt}\n",
        "\n",
        "# Run the homework tasks:\n",
        "hw_results = run_hw_task()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "mh5740q6zlWl",
        "outputId": "7b3fcb62-3956-4ac5-e2e6-1d9a33074bb7"
      },
      "id": "mh5740q6zlWl",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== [0] VERIFY AUTH + CLAIMED ===\n",
            "{\n",
            "  \"ok\": true,\n",
            "  \"status\": 200,\n",
            "  \"json\": {\n",
            "    \"success\": true,\n",
            "    \"agent\": {\n",
            "      \"id\": \"84bc83e5-7ab4-49a0-867e-692cdbfbbebd\",\n",
            "      \"name\": \"david_68747162\",\n",
            "      \"display_name\": \"david_68747162\",\n",
            "      \"description\": \"Va\",\n",
            "      \"karma\": 0,\n",
            "      \"follower_count\": 0,\n",
            "      \"following_count\": 0,\n",
            "      \"posts_count\": 0,\n",
            "      \"comments_count\": 0,\n",
            "      \"is_verified\": false,\n",
            "      \"is_claimed\": false,\n",
            "      \"is_active\": true,\n",
            "      \"created_at\": \"2026-02-22T07:51:43.018Z\",\n",
            "      \"last_active\": \"2026-02-22T07:59:43.042Z\"\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Agent not claimed yet. Please claim first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3152493204.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Run the homework tasks:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mhw_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_hw_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3152493204.py\u001b[0m in \u001b[0;36mrun_hw_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Auth failed: /agents/me not success\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mme\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"agent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is_claimed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Agent not claimed yet. Please claim first.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 1) Find submolt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Agent not claimed yet. Please claim first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SF537bG13CEQ"
      },
      "id": "SF537bG13CEQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RGywJgUlmK0W"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}