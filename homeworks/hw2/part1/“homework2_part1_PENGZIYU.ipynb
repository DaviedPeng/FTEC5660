{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RRbStil_qkQc",
        "kCENjOq6owDd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2-Part1-PENGZIYU"
      ],
      "metadata": {
        "id": "tFaf7VErZ1Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "I3g3k3W-qfAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "6vsESFZylO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install 'markitdown[pdf]'\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ],
      "metadata": {
        "id": "Hrdfpmv9nMpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e4bd44-dc2e-4d3d-beeb-ec8ebc238999"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting markitdown[pdf]\n",
            "  Downloading markitdown-0.1.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
            "Collecting magika~=0.6.1 (from markitdown[pdf])\n",
            "  Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting markdownify (from markitdown[pdf])\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
            "Collecting pdfminer-six>=20251230 (from markitdown[pdf])\n",
            "  Downloading pdfminer_six-20260107-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pdfplumber>=0.11.9 (from markitdown[pdf])\n",
            "  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
            "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown[pdf])\n",
            "  Downloading onnxruntime-1.24.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20251230->markitdown[pdf]) (43.0.3)\n",
            "Collecting pdfminer-six>=20251230 (from markitdown[pdf])\n",
            "  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.9->markitdown[pdf])\n",
            "  Downloading pypdfium2-5.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
            "Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl (15.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading markitdown-0.1.5-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, onnxruntime, markdownify, pdfminer-six, magika, pdfplumber, markitdown\n",
            "Successfully installed magika-0.6.3 markdownify-1.2.2 markitdown-0.1.5 onnxruntime-1.24.2 pdfminer-six-20251230 pdfplumber-0.11.9 pypdfium2-5.5.0\n",
            "Collecting langchain_mcp_adapters\n",
            "  Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-4.2.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.10-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.13)\n",
            "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.13.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.41.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n",
            "Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading langchain_google_genai-4.2.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.10-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-openai, langchain_mcp_adapters, langchain_google_genai\n",
            "Successfully installed filetype-1.2.0 langchain-openai-1.1.10 langchain_google_genai-4.2.1 langchain_mcp_adapters-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
        "\n",
        "\n",
        "1.   Look for the key icon on the left panel of your colab.\n",
        "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
        "3. Copy your key to `Value`.\n",
        "\n",
        "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
        "\n"
      ],
      "metadata": {
        "id": "BUav-7KdaY_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-lite\",\n",
        "    contents=\"Explain how flash attention works in a two sentences.\",\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFQOskcSwHno",
        "outputId": "1db3434f-30c3-41a4-dc1d-aff498d21252"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FlashAttention optimizes the attention mechanism by tiling and reordering computations, avoiding materializing the large attention matrix in full. This significantly reduces memory reads and writes, leading to faster execution and lower memory usage, especially for long sequences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download sample CVs"
      ],
      "metadata": {
        "id": "RRbStil_qkQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading sample_cv.pdf\n",
        "The codes below download the sample CV\n"
      ],
      "metadata": {
        "id": "kCENjOq6owDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCCp8DwPF4L",
        "outputId": "7c07d2eb-efc8-4ac3-9c08-670141d7b8aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
            "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
            "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
            "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
            "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
            "To: /content/downloaded_cvs/CV_1.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 4.09MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
            "To: /content/downloaded_cvs/CV_2.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 3.23MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
            "To: /content/downloaded_cvs/CV_3.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 3.06MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
            "To: /content/downloaded_cvs/CV_4.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 2.81MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
            "To: /content/downloaded_cvs/CV_5.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 3.19MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['downloaded_cvs/CV_1.pdf',\n",
              " 'downloaded_cvs/CV_2.pdf',\n",
              " 'downloaded_cvs/CV_3.pdf',\n",
              " 'downloaded_cvs/CV_4.pdf',\n",
              " 'downloaded_cvs/CV_5.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ“„ {pdf_name}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result.text_content)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2akmVn9LODIu",
        "outputId": "9d6b0eee-ce1b-47e1-888b-d0c69b3055e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ğŸ“„ CV_1.pdf\n",
            "================================================================================\n",
            "|     |     |     |     | John         |           | Smith        |                   |     |     |\n",
            "| --- | --- | --- | --- | ------------ | --------- | ------------ | ----------------- | --- | --- |\n",
            "|     |     |     |     | Marketing    |           | Professional |                   |     |     |\n",
            "|     |     |     |     | + Singapore, | Singapore |              | (cid:209) Kowloon |     |     |\n",
            "Experience\n",
            "|                |                  |     |          |                     |              |            |     | 2020 â€“ | Present |\n",
            "| -------------- | ---------------- | --- | -------- | ------------------- | ------------ | ---------- | --- | ------ | ------- |\n",
            "| Engineer,      | ByteDance        |     |          |                     |              |            |     |        |         |\n",
            "| â€¢ Worked       | in a fast-paced, |     | global   | technology          | environment. |            |     |        |         |\n",
            "| â€¢ Collaborated | across           |     | teams to | support large-scale |              | platforms. |     |        |         |\n",
            "â€¢ Applied analytical and problem-solving skills in production systems.\n",
            "Education\n",
            "| McGill   | University |       |              |     |     |     |     | Graduated | 2009 |\n",
            "| -------- | ---------- | ----- | ------------ | --- | --- | --- | --- | --------- | ---- |\n",
            "| Bachelor | of Science | (BSc) | in Marketing |     |     |     |     |           |      |\n",
            "Skills\n",
            "| Content | Creation | SEO | Social | Media |     |     |     |     |     |\n",
            "| ------- | -------- | --- | ------ | ----- | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_2.pdf\n",
            "================================================================================\n",
            "| Minh | Pham |     |     |     |     |     |\n",
            "| ---- | ---- | --- | --- | --- | --- | --- |\n",
            "Design Professional\n",
            "| Beijing,     | China | Hong     | Kong     |               |        |              |                |\n",
            "| ------------ | ---------------- | -------- | ------------- | ------ | ------------ | -------------- |\n",
            "| Professional | Experience       |          |               |        |              |                |\n",
            "| Manager,     | BCG              |          |               |        |              | 2022 â€“ Present |\n",
            "| â€¢ Led        | cross-functional | teams on | client-facing | design | initiatives. |                |\n",
            "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
            "| â€¢ Applied | design thinking | to business | and | strategy | problems. |             |\n",
            "| --------- | --------------- | ----------- | --- | -------- | --------- | ----------- |\n",
            "| Analyst,  | Tencent         |             |     |          |           | 2013 â€“ 2017 |\n",
            "â€¢ Conducted market and product analysis to support decision-making.\n",
            "| â€¢ Collaborated | with    | design and   | engineering | teams.      |     |     |\n",
            "| -------------- | ------- | ------------ | ----------- | ----------- | --- | --- |\n",
            "| â€¢ Produced     | reports | and insights | for senior  | leadership. |     |     |\n",
            "Education\n",
            "| BSc in         | Design  |      |     |     |     | 2011 |\n",
            "| -------------- | ------- | ---- | --- | --- | --- | ---- |\n",
            "| The University | of Hong | Kong |     |     |     |      |\n",
            "Skills\n",
            "| â€¢ UI/UX | Design |     |     |     |     |     |\n",
            "| ------- | ------ | --- | --- | --- | --- | --- |\n",
            "â€¢ Prototyping\n",
            "| â€¢ Graphic | Design |     |     |     |     |     |\n",
            "| --------- | ------ | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_3.pdf\n",
            "================================================================================\n",
            "| Wei Zhang    |              |           |     |     |     | Munich, Germany   |\n",
            "| ------------ | ------------ | --------- | --- | --- | --- | ----------------- |\n",
            "| Consulting   | Professional |           |     |     |     | Sydney (Hometown) |\n",
            "| Professional | Experience   |           |     |     |     |                   |\n",
            "| 2013         | â€“ Present    | Engineer, | PwC |     |     |                   |\n",
            "â€¢ Supportedconsultingengagementsacrossmultipleclient\n",
            "projects.\n",
            "|     |     | â€¢ Performed | data analysis | to inform | strategic recommen- |     |\n",
            "| --- | --- | ----------- | ------------- | --------- | ------------------- | --- |\n",
            "dations.\n",
            "|     |     | â€¢ Collaborated  | with         | cross-functional | teams in | a profes- |\n",
            "| --- | --- | --------------- | ------------ | ---------------- | -------- | --------- |\n",
            "|     |     | sional services | environment. |                  |          |           |\n",
            "Education\n",
            "| 2015 |     | BSc in Consulting |          |     |     |     |\n",
            "| ---- | --- | ----------------- | -------- | --- | --- | --- |\n",
            "|      |     | University        | of Tokyo |     |     |     |\n",
            "Skills\n",
            "| Analytical |     |     | Data Analysis,       | Problem | Solving |     |\n",
            "| ---------- | --- | --- | -------------------- | ------- | ------- | --- |\n",
            "| Business   |     |     | Strategy, PowerPoint |         |         |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_4.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- | --- | --- |\n",
            "Legal Professional\n",
            "| Singapore    | (Hometown) | | Singapore              |           | / Philippines |             |        |             |     |         |\n",
            "| ------------ | ---------- | ------------------------ | --------- | ------------- | ----------- | ------ | ----------- | --- | ------- |\n",
            "| Professional |            | Experience               |           |               |             |        |             |     |         |\n",
            "| 2021         | â€“ 2027     | Senior                   | Engineer, | Microsoft     |             |        |             |     |         |\n",
            "|              |            | â€¢ Led compliance-focused |           |               | initiatives | within | large-scale |     | techni- |\n",
            "cal teams.\n",
            "â€¢ Advisedonregulatory,legal,andriskconsiderationsforcom-\n",
            "plex systems.\n",
            "|     |     | â€¢ Worked | at the | intersection |     | of law, | technology, | and | gover- |\n",
            "| --- | --- | -------- | ------ | ------------ | --- | ------- | ----------- | --- | ------ |\n",
            "nance.\n",
            "| 2020 | â€“ 2023 | Consultant, | StartupXYZ |               |     |            |                 |     |      |\n",
            "| ---- | ------ | ----------- | ---------- | ------------- | --- | ---------- | --------------- | --- | ---- |\n",
            "|      |        | â€¢ Provided  | legal      | and strategic |     | consulting | for early-stage |     | com- |\n",
            "panies.\n",
            "|     |     | â€¢ Supported | contract | review, |     | compliance, | and operational |     | risk |\n",
            "| --- | --- | ----------- | -------- | ------- | --- | ----------- | --------------- | --- | ---- |\n",
            "management.\n",
            "|     |     | â€¢ Engaged | with | cross-functional |     | and | international | stakehold- |     |\n",
            "| --- | --- | --------- | ---- | ---------------- | --- | --- | ------------- | ---------- | --- |\n",
            "ers.\n",
            "Education\n",
            "2021\n",
            "|     |     | PhD in   | Legal      | Studies |     |     |     |     |     |\n",
            "| --- | --- | -------- | ---------- | ------- | --- | --- | --- | --- | --- |\n",
            "|     |     | Tsinghua | University |         |     |     |     |     |     |\n",
            "Skills\n",
            "|     |     | Compliance,   | Litigation, |           | Contract | Review    |     |     |     |\n",
            "| --- | --- | ------------- | ----------- | --------- | -------- | --------- | --- | --- | --- |\n",
            "|     |     | Web3, Machine |             | Learning, | Quantum  | Computing |     |     |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_5.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- |\n",
            "AI Professional\n",
            "| London     | | Hong Kong | | Singapore | (Hometown) |              |               |                |               |\n",
            "| ---------- | ----------- | ----------- | ---------- | ------------ | ------------- | -------------- | ------------- |\n",
            "| Core       | Skills      |             |            | Professional | Experience    |                |               |\n",
            "| Machine    | Learning    | & AI        |            | Senior       | Engineer      |                |               |\n",
            "|            |             |             |            | EY           |               |                | Current       |\n",
            "| â€¢ Advanced | AI Systems  |             |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Designed   | and evaluated | AI-driven      | solutions for |\n",
            "|            |             |             |            | enterprise   | clients.      |                |               |\n",
            "| â€¢ Machine  | Learning    | (ML)        |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Applied    | ML techniques | to large-scale | business      |\n",
            "| â€¢ Natural  | Language    | Processing  | (NLP)      | problems.    |               |                |               |\n",
            "Consultant\n",
            "| Frameworks   | &   | Tools |     |             |             |          |             |\n",
            "| ------------ | --- | ----- | --- | ----------- | ----------- | -------- | ----------- |\n",
            "|              |     |       |     | StartupXYZ  |             |          | 2019 â€“ 2021 |\n",
            "| â€¢ TensorFlow |     |       |     | â€¢ Provided  | AI and data | strategy | advisory to |\n",
            "|              |     |       |     | early-stage | companies.  |          |             |\n",
            "â€¢ PyTorch\n",
            "Senior Analyst\n",
            "|     |     |     |     | DataForge |     | 2016 | â€“ Present |\n",
            "| --- | --- | --- | --- | --------- | --- | ---- | --------- |\n",
            "â€¢ Python\n",
            "|     |     |     |     | â€¢ Conducted | advanced | data analysis | and model |\n",
            "| --- | --- | --- | --- | ----------- | -------- | ------------- | --------- |\n",
            "evaluation.\n",
            "Lead Scientist\n",
            "Education\n",
            "|     |     |     |     | UrbanFlow |     |     | 2010 â€“ 2017 |\n",
            "| --- | --- | --- | --- | --------- | --- | --- | ----------- |\n",
            "PhD in Artificial Intelligence â€¢ Led research initiatives in applied AI systems.\n",
            "| University | of Tokyo |     |     |            |                    |                |     |\n",
            "| ---------- | -------- | --- | --- | ---------- | ------------------ | -------------- | --- |\n",
            "| 2012       |          |     |     | â€¢ Mentored | junior researchers | and engineers. |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to our MCP server\n",
        "\n",
        "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
        "\n",
        "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
      ],
      "metadata": {
        "id": "VA2GvPWTQFt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check which tools that the MCP server provide"
      ],
      "metadata": {
        "id": "5mbkH9xHXfmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "for tool in mcp_tools:\n",
        "    print(tool.name)\n",
        "    print(tool.description)\n",
        "    print(tool.args)\n",
        "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h0311KbN9A3",
        "outputId": "d669aa81-7c06-4f2c-fbb8-4e6d5382cba4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search_facebook_users\n",
            "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
            "\n",
            "Args:\n",
            "    q: Search query string (case-insensitive, matches any part of display name)\n",
            "       Examples: \"John\", \"john smith\", \"Smith\"\n",
            "    limit: Maximum number of results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of user dictionaries, each containing:\n",
            "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
            "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
            "    - city (str): Current city of residence\n",
            "    - country (str): Country of residence\n",
            "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_facebook_users(\"Alex Chan\", limit=5)\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
            "    personal information, location, and social connections. Handles typos and variations.\n",
            "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_profile\n",
            "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
            "\n",
            "Args:\n",
            "    user_id: Facebook user ID obtained from search_facebook_users()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): Facebook user ID\n",
            "    - display_name (str): Public display name (may be nickname)\n",
            "    - original_name (str): Original/legal name from LinkedIn\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - hometown (str|None): City/region where user grew up\n",
            "    - bio (str): Personal biography/interests\n",
            "    - status (str|None): Relationship status (Single, Married, etc.)\n",
            "    - education (str|None): Highest education level\n",
            "    - current_job (str|None): Current job title\n",
            "    - current_company (str|None): Current employer\n",
            "    - interests (str): Comma-separated hobbies/interests\n",
            "    - friends (List[int]): List of friend user IDs\n",
            "    - posts (List[dict]): Recent posts with id and content\n",
            "    \n",
            "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_facebook_profile(123)\n",
            "    â†’ {\n",
            "        \"id\": 123,\n",
            "        \"display_name\": \"Sam Chan\",\n",
            "        \"original_name\": \"Alex Chan\",\n",
            "        \"city\": \"Hong Kong\",\n",
            "        \"hometown\": \"Kowloon\",\n",
            "        \"bio\": \"Software professional | Photography enthusiast\",\n",
            "        \"status\": \"Married\",\n",
            "        \"current_job\": \"Senior Engineer\",\n",
            "        \"current_company\": \"Google\",\n",
            "        \"friends\": [124, 125, 126],\n",
            "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Verify candidate's personal details, check for name discrepancies,\n",
            "    validate current employment, and assess social connections.\n",
            "{'user_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_mutual_friends\n",
            "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
            "\n",
            "Args:\n",
            "    user_id_1: First Facebook user ID\n",
            "    user_id_2: Second Facebook user ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - user_1_id (int): First user's ID\n",
            "    - user_2_id (int): Second user's ID\n",
            "    - mutual_friends (List[int]): List of shared friend IDs\n",
            "    - mutual_count (int): Number of mutual friends\n",
            "    \n",
            "    Returns {\"error\": \"...\"} if either user not found.\n",
            "\n",
            "Example:\n",
            "    get_facebook_mutual_friends(123, 456)\n",
            "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
            "\n",
            "Use case:\n",
            "    Verify professional or personal relationships claimed in CV/references.\n",
            "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "search_linkedin_people\n",
            "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
            "\n",
            "Args:\n",
            "    q: Search query (matches name, headline, summary, or skill names)\n",
            "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
            "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
            "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
            "    industry: Filter by industry (optional, case-insensitive)\n",
            "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
            "    limit: Maximum results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of profile dictionaries, each containing:\n",
            "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline/title\n",
            "    - industry (str): Industry sector\n",
            "    - location (str): \"City, Country\" format\n",
            "    - years_experience (int): Total years of work experience\n",
            "    - match_type (str): \"exact\" or \"fuzzy\"\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
            "    Use location filter to narrow down results when common names exist. Handles typos.\n",
            "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_profile\n",
            "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): LinkedIn profile ID\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - industry (str): Primary industry\n",
            "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
            "    - years_experience (int): Total years of professional experience\n",
            "    - summary (str): Professional summary/bio\n",
            "    \n",
            "    - skills (List[dict]): Each containing:\n",
            "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
            "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
            "    \n",
            "    - experience (List[dict]): Work history, each containing:\n",
            "        * company (str): Employer name\n",
            "        * title (str): Job title\n",
            "        * seniority (str): Level (junior, mid, senior)\n",
            "        * start_year (int): Employment start year\n",
            "        * end_year (int|None): Employment end year (None if current)\n",
            "        * is_current (bool): Whether currently employed here\n",
            "    \n",
            "    - education (List[dict]): Academic history, each containing:\n",
            "        * school (str): Institution name\n",
            "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
            "        * field (str): Field of study\n",
            "        * start_year (int): Start year\n",
            "        * end_year (int): Graduation year\n",
            "    \n",
            "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_profile(456)\n",
            "    â†’ {\n",
            "        \"id\": 456,\n",
            "        \"name\": \"Alex Chan\",\n",
            "        \"headline\": \"Senior Software Engineer\",\n",
            "        \"years_experience\": 8,\n",
            "        \"skills\": [\n",
            "            {\"name\": \"Python\", \"proficiency\": 5},\n",
            "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
            "        ],\n",
            "        \"experience\": [\n",
            "            {\n",
            "                \"company\": \"Google\",\n",
            "                \"title\": \"Senior Engineer\",\n",
            "                \"seniority\": \"senior\",\n",
            "                \"start_year\": 2020,\n",
            "                \"end_year\": None,\n",
            "                \"is_current\": True\n",
            "            }\n",
            "        ],\n",
            "        \"education\": [\n",
            "            {\n",
            "                \"school\": \"HKUST\",\n",
            "                \"degree\": \"BSc\",\n",
            "                \"field\": \"Computer Science\",\n",
            "                \"start_year\": 2010,\n",
            "                \"end_year\": 2014\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Primary tool for CV verification - compare claimed experience, education,\n",
            "    skills, and employment dates against LinkedIn ground truth.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_interactions\n",
            "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - profile_id (int): The person's LinkedIn ID\n",
            "    - post_count (int): Number of posts made\n",
            "    - total_likes (int): Total likes received across all posts\n",
            "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
            "    - engagement_score (float): Likes per post ratio\n",
            "    \n",
            "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_interactions(456)\n",
            "    â†’ {\n",
            "        \"profile_id\": 456,\n",
            "        \"post_count\": 10,\n",
            "        \"total_likes\": 150,\n",
            "        \"liked_by\": [123, 124, 125],\n",
            "        \"engagement_score\": 15.0\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Assess professional network strength and content engagement.\n",
            "    Verify connections to claimed colleagues or industry peers.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A simple agent using tools from the MCP server\n"
      ],
      "metadata": {
        "id": "ABoe2-qfXl7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Define a local tool\n",
        "# ---------------------------\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to a person by name.\"\"\"\n",
        "    return f\"Hello, {name}! ğŸ‘‹\"\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Load MCP tools + merge\n",
        "# ---------------------------\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "tools = mcp_tools + [say_hello]\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Initialize Gemini (tool-enabled) or deepseek\n",
        "# ---------------------------\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash-lite\",\n",
        "    google_api_key=GEMINI_API_KEY,\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Single-step invocation\n",
        "# ---------------------------\n",
        "query = \"Say hello to Bao using tool, then search for someone named Alice on Facebook.\"\n",
        "\n",
        "response = llm_with_tools.invoke([\n",
        "    HumanMessage(content=query)\n",
        "])\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtTjwFKhTKn3",
        "outputId": "bd1068a3-ef1d-4ec6-8d09-380cdfb32d75"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={'function_call': {'name': 'search_facebook_users', 'arguments': '{\"q\": \"Alice\"}'}} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c8ac2-e40e-79f1-9e22-0ce88ef25458-0' tool_calls=[{'name': 'say_hello', 'args': {'name': 'Bao'}, 'id': 'e476db8f-791c-4102-b23c-1b9d687b32d9', 'type': 'tool_call'}, {'name': 'search_facebook_users', 'args': {'q': 'Alice'}, 'id': '80814783-c3c6-4716-8d9d-607745151dc7', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 2852, 'output_tokens': 33, 'total_tokens': 2885, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This block provides you some tests to get faminilar with our MCP server\n",
        "\n",
        "# # Test 1: Search Facebook users (exact match)\n",
        "# await tools[0].ainvoke({'q': \"Alex Chan\", 'limit': 5})\n",
        "\n",
        "# # Test 2: Search Facebook users (fuzzy match with typo)\n",
        "# await tools[0].ainvoke({'q': \"Alx Chn\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 3: Get Facebook profile\n",
        "# await tools[1].ainvoke({'user_id': 123})\n",
        "\n",
        "# # Test 4: Get Facebook mutual friends\n",
        "# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
        "\n",
        "# # Test 5: Search LinkedIn people (exact match)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
        "\n",
        "# # Test 6: Search LinkedIn people (fuzzy match with typo)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 7: Get LinkedIn profile\n",
        "# await tools[4].ainvoke({'person_id': 456})\n",
        "\n",
        "# Test 8: Get LinkedIn interactions\n",
        "await tools[5].ainvoke({'person_id': 456})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLeoXGrqesW",
        "outputId": "f41572ca-0528-4efa-c9b4-9b0bd8acbdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'text',\n",
              "  'text': '{\"profile_id\":456,\"post_count\":4,\"total_likes\":5,\"liked_by\":[4390,3622,7500,4269,8464],\"engagement_score\":1.25}',\n",
              "  'id': 'lc_cf7cf5a1-dc1c-470e-b927-19d225e687f5'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation code\n",
        "\n",
        "In the test phase, you will be given 5 CV files with fixed names:\n",
        "\n",
        "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
        "\n",
        "Your system must process these CVs and output a list of 5 scores,\n",
        "one score per CV, in the same order:\n",
        "\n",
        "    scores = [s1, s2, s3, s4, s5]\n",
        "\n",
        "Each score must be a float in the range [0, 1], representing the\n",
        "reliability or confidence that the CV is valid (or meets the task criteria).\n",
        "\n",
        "The ground-truth labels are binary:\n",
        "\n",
        "    groundtruth = [0 or 1, ..., 0 or 1]\n",
        "\n",
        "Each CV is evaluated independently using a threshold of 0.5:\n",
        "\n",
        "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
        "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
        "- Otherwise â†’ No credit\n",
        "\n",
        "In other words, 0.5 is the decision threshold.\n",
        "\n",
        "- Each CV contributes equally.\n",
        "- Final score = (number of correct decisions) / 5\n"
      ],
      "metadata": {
        "id": "UqO99iOlq6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install markitdown rapidfuzz langchain langchain-core langchain-google-genai langchain-mcp-adapters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CrCVgcr1VJn",
        "outputId": "d7df1ee3-1525-4f44-ec5c-3b2f6f479fff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/3.2 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "if not GEMINI_API_KEY:\n",
        "    raise ValueError(\"æ²¡è¯»åˆ° GEMINI_API_KEYã€‚è¯·åœ¨ Colab å·¦ä¾§ğŸ”‘Secrets æ·»åŠ  GEMINI_API_KEY\")\n",
        "print(\"âœ… GEMINI_API_KEY loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGCeNk6q1VBA",
        "outputId": "218fa19b-ba20-4223-8d8a-38e0eea39da2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… GEMINI_API_KEY loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "print(\"âœ… MCP tools loaded:\", [t.name for t in mcp_tools])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C8l7I-E1Uy8",
        "outputId": "e029fddb-46b9-47c6-bf33-d6534d9e244c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… MCP tools loaded: ['search_facebook_users', 'get_facebook_profile', 'get_facebook_mutual_friends', 'search_linkedin_people', 'get_linkedin_profile', 'get_linkedin_interactions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash-lite\",\n",
        "    google_api_key=GEMINI_API_KEY,\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# ç»‘å®šå·¥å…·ï¼ˆè®©æ¨¡å‹èƒ½äº§ç”Ÿ tool_callsï¼‰\n",
        "llm_with_tools = llm.bind_tools(mcp_tools)\n",
        "print(\"âœ… LLM ready:\", llm.model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a63kNg8V1jsl",
        "outputId": "bbd0bf68-fc70-4f2c-af2c-39f3f130ec35"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LLM ready: gemini-2.5-flash-lite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# å¼ºåˆ¶æŒ‰ CV_1.pdf ... CV_5.pdf\n",
        "expected_files = [f\"CV_{i}.pdf\" for i in range(1, 6)]\n",
        "missing = [f for f in expected_files if not os.path.exists(os.path.join(cv_dir, f))]\n",
        "if missing:\n",
        "    raise FileNotFoundError(f\"ç¼ºå°‘CVæ–‡ä»¶ï¼š{missing}ï¼Œè¯·ç¡®è®¤éƒ½åœ¨ {cv_dir}/ ä¸‹\")\n",
        "\n",
        "all_cvs = []\n",
        "for fname in expected_files:\n",
        "    pdf_path = os.path.join(cv_dir, fname)\n",
        "    result = md.convert(pdf_path)\n",
        "    all_cvs.append({\"file\": fname, \"text\": result.text_content})\n",
        "\n",
        "print(\"âœ… Loaded CVs:\", [cv[\"file\"] for cv in all_cvs])\n",
        "assert len(all_cvs) == 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxnR5UtQ1oP-",
        "outputId": "2d141f7d-ae7f-4529-9389-036232e73dbc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded CVs: ['CV_1.pdf', 'CV_2.pdf', 'CV_3.pdf', 'CV_4.pdf', 'CV_5.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def norm(s):\n",
        "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip().lower()\n",
        "\n",
        "def guess_name(text: str):\n",
        "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "    head = lines[:25]\n",
        "    for l in head:\n",
        "        m = re.search(r\"(Name|å§“å)\\s*[:ï¼š]\\s*(.+)$\", l, re.IGNORECASE)\n",
        "        if m:\n",
        "            cand = re.sub(r\"[^A-Za-z\\-\\s]\", \" \", m.group(2))\n",
        "            cand = re.sub(r\"\\s+\", \" \", cand).strip()\n",
        "            if 2 <= len(cand) <= 60:\n",
        "                return cand\n",
        "    if head:\n",
        "        cand = re.sub(r\"[^A-Za-z\\-\\s]\", \" \", head[0])\n",
        "        cand = re.sub(r\"\\s+\", \" \", cand).strip()\n",
        "        if 2 <= len(cand) <= 60 and re.fullmatch(r\"[A-Za-z][A-Za-z\\-\\s]{1,59}\", cand):\n",
        "            return cand\n",
        "    return None\n",
        "\n",
        "def guess_location(text: str):\n",
        "    low = text.lower()\n",
        "    for loc in [\"hong kong\",\"singapore\",\"tokyo\",\"japan\",\"china\",\"beijing\",\"shanghai\",\"shenzhen\",\"kowloon\"]:\n",
        "        if loc in low:\n",
        "            return \" \".join([w.capitalize() for w in loc.split()])\n",
        "    return None"
      ],
      "metadata": {
        "id": "3s67wVUN1oF2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "tool_map = {t.name: t for t in mcp_tools}\n",
        "print(\"âœ… tool_map:\", list(tool_map.keys()))\n",
        "\n",
        "def _allowed_keys(tool):\n",
        "    try:\n",
        "        schema = tool.args_schema.schema()\n",
        "        return set(schema.get(\"properties\", {}).keys())\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _maybe_parse_mcp_content(res):\n",
        "    \"\"\"\n",
        "    ä½ çš„ MCP è¿”å›ç»å¸¸æ˜¯ï¼š\n",
        "      [{\"type\":\"text\",\"text\":\"...json...\",\"id\":\"lc_...\"}]\n",
        "    æˆ‘ä»¬æŠŠ text é‡Œçš„ JSON è‡ªåŠ¨è§£ææˆ list/dictã€‚\n",
        "    \"\"\"\n",
        "    if isinstance(res, list) and len(res) > 0 and isinstance(res[0], dict):\n",
        "        # å…¸å‹ MCP: [{\"type\":\"text\",\"text\":\"[...]\",\"id\":\"lc_...\"}]\n",
        "        if \"text\" in res[0] and isinstance(res[0][\"text\"], str):\n",
        "            s = res[0][\"text\"].strip()\n",
        "            if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"{\") and s.endswith(\"}\")):\n",
        "                try:\n",
        "                    return json.loads(s)\n",
        "                except Exception:\n",
        "                    return res\n",
        "    return res\n",
        "\n",
        "async def run_tool_calls(tool_calls):\n",
        "    tool_messages = []\n",
        "    audit_log = []\n",
        "\n",
        "    for tc in tool_calls:\n",
        "        name = tc[\"name\"]\n",
        "        args = tc.get(\"args\", {}) or {}\n",
        "        tool = tool_map.get(name)\n",
        "\n",
        "        if tool is None:\n",
        "            parsed = {\"error\": f\"tool '{name}' not found\"}\n",
        "        else:\n",
        "            # å‚æ•°æ¸…æ´—ï¼ˆé˜²æ­¢ LLM ä¹±å¡ city ä¹‹ç±»ï¼‰\n",
        "            allow = _allowed_keys(tool)\n",
        "            if allow is not None:\n",
        "                args = {k: v for k, v in args.items() if k in allow}\n",
        "\n",
        "            try:\n",
        "                raw = await tool.ainvoke(args)\n",
        "                parsed = _maybe_parse_mcp_content(raw)\n",
        "            except Exception as e:\n",
        "                parsed = {\"error\": f\"{type(e).__name__}: {e}\", \"args_used\": args}\n",
        "\n",
        "        audit_log.append({\"tool\": name, \"args\": args, \"result\": parsed})\n",
        "        tool_messages.append(\n",
        "            ToolMessage(\n",
        "                tool_call_id=tc[\"id\"],\n",
        "                content=json.dumps(parsed, ensure_ascii=False)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return tool_messages, audit_log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJSTAhCJ1n9Q",
        "outputId": "3f9b8c74-f7c3-42d0-98b5-583164aeaf14"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… tool_map: ['search_facebook_users', 'get_facebook_profile', 'get_facebook_mutual_friends', 'search_linkedin_people', 'get_linkedin_profile', 'get_linkedin_interactions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AGENT_PROMPT = \"\"\"\n",
        "You are a CV verification agent (KYC-style).\n",
        "\n",
        "Hard rules:\n",
        "- Use tools to find the most similar LinkedIn and Facebook profiles.\n",
        "- If no exact match, pick the most similar existing profile (do NOT reject).\n",
        "- Never reject a CV due to internal inconsistencies; record issues and LOWER confidence.\n",
        "\n",
        "Mandatory tool sequence (unless search returns empty list):\n",
        "1) search_linkedin_people -> then get_linkedin_profile(best_id)\n",
        "2) search_facebook_users  -> then get_facebook_profile(best_id)\n",
        "\n",
        "After you have both profiles (or confirmed empty search), STOP and summarize:\n",
        "- selected profiles (id + name)\n",
        "- key evidence\n",
        "- key discrepancies\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Bgr9ZmFk2C48"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "\n",
        "def _first_candidate_id(search_result):\n",
        "    \"\"\"\n",
        "    ç°åœ¨ search_result å·²ç»è¢« run_tool_calls è§£ææˆ list[dict] äº†ã€‚\n",
        "    å–ç¬¬ä¸€ä¸ªå€™é€‰çš„ idï¼ˆåº”ä¸º intï¼‰\n",
        "    \"\"\"\n",
        "    if isinstance(search_result, list) and search_result and isinstance(search_result[0], dict):\n",
        "        return search_result[0].get(\"id\")\n",
        "    return None\n",
        "\n",
        "async def run_agent_for_cv(cv: dict, max_iters: int = 8):\n",
        "    text = cv[\"text\"]\n",
        "    name_guess = guess_name(text)\n",
        "    loc_guess = guess_location(text)\n",
        "    excerpt = text[:2000]\n",
        "\n",
        "    msgs = [\n",
        "        HumanMessage(content=AGENT_PROMPT),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "CV file: {cv['file']}\n",
        "Guessed name: {name_guess}\n",
        "Guessed location: {loc_guess}\n",
        "\n",
        "CV excerpt:\n",
        "{excerpt}\n",
        "\n",
        "Task: Use tools to verify this CV.\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    audit = []\n",
        "    have_li_profile = False\n",
        "    have_fb_profile = False\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        ai = llm_with_tools.invoke(msgs)\n",
        "        msgs.append(ai)\n",
        "\n",
        "        tool_calls = getattr(ai, \"tool_calls\", None) or []\n",
        "        if not tool_calls:\n",
        "            break\n",
        "\n",
        "        tool_msgs, step_audit = await run_tool_calls(tool_calls)\n",
        "        audit.extend(step_audit)\n",
        "        msgs.extend(tool_msgs)\n",
        "\n",
        "        # ---- å¼ºåˆ¶è¡¥é½ LinkedIn profile ----\n",
        "        if not have_li_profile:\n",
        "            li_search = next((x for x in reversed(audit) if x[\"tool\"] == \"search_linkedin_people\"), None)\n",
        "            if li_search:\n",
        "                pid = _first_candidate_id(li_search[\"result\"])\n",
        "                # pid åº”è¯¥æ˜¯ intï¼ˆä¾‹å¦‚ 9/31/203ï¼‰\n",
        "                if isinstance(pid, int):\n",
        "                    li_prof = await tool_map[\"get_linkedin_profile\"].ainvoke({\"person_id\": pid})\n",
        "                    li_prof_parsed = li_prof\n",
        "                    # ä¿é™©ï¼šå¦‚æœ get è¿”å›ä¹Ÿæ˜¯ text chunkï¼Œå°±è§£æä¸€ä¸‹\n",
        "                    if isinstance(li_prof, list) and li_prof and isinstance(li_prof[0], dict) and \"text\" in li_prof[0]:\n",
        "                        try:\n",
        "                            li_prof_parsed = json.loads(li_prof[0][\"text\"])\n",
        "                        except Exception:\n",
        "                            li_prof_parsed = li_prof\n",
        "\n",
        "                    audit.append({\"tool\": \"get_linkedin_profile\", \"args\": {\"person_id\": pid}, \"result\": li_prof_parsed})\n",
        "                    msgs.append(ToolMessage(tool_call_id=\"forced_li\", content=json.dumps(li_prof_parsed, ensure_ascii=False)))\n",
        "                    have_li_profile = True\n",
        "\n",
        "        # ---- å¼ºåˆ¶è¡¥é½ Facebook profile ----\n",
        "        if not have_fb_profile:\n",
        "            fb_search = next((x for x in reversed(audit) if x[\"tool\"] == \"search_facebook_users\"), None)\n",
        "            if fb_search:\n",
        "                uid = _first_candidate_id(fb_search[\"result\"])\n",
        "                if isinstance(uid, int):\n",
        "                    fb_prof = await tool_map[\"get_facebook_profile\"].ainvoke({\"user_id\": uid})\n",
        "                    fb_prof_parsed = fb_prof\n",
        "                    if isinstance(fb_prof, list) and fb_prof and isinstance(fb_prof[0], dict) and \"text\" in fb_prof[0]:\n",
        "                        try:\n",
        "                            fb_prof_parsed = json.loads(fb_prof[0][\"text\"])\n",
        "                        except Exception:\n",
        "                            fb_prof_parsed = fb_prof\n",
        "\n",
        "                    audit.append({\"tool\": \"get_facebook_profile\", \"args\": {\"user_id\": uid}, \"result\": fb_prof_parsed})\n",
        "                    msgs.append(ToolMessage(tool_call_id=\"forced_fb\", content=json.dumps(fb_prof_parsed, ensure_ascii=False)))\n",
        "                    have_fb_profile = True\n",
        "\n",
        "        if have_li_profile and have_fb_profile:\n",
        "            break\n",
        "\n",
        "    final = llm_with_tools.invoke(msgs)\n",
        "\n",
        "    return {\n",
        "        \"file\": cv[\"file\"],\n",
        "        \"name_guess\": name_guess,\n",
        "        \"location_guess\": loc_guess,\n",
        "        \"final_text\": final.content,\n",
        "        \"audit_log\": audit\n",
        "    }"
      ],
      "metadata": {
        "id": "l_EH_VL_6tV6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rapidfuzz import fuzz\n",
        "import re\n",
        "\n",
        "def find_first(audit_log, tool_name):\n",
        "    for x in audit_log:\n",
        "        if x[\"tool\"] == tool_name:\n",
        "            return x[\"result\"]\n",
        "    return None\n",
        "\n",
        "def clamp(x, lo=0.0, hi=1.0):\n",
        "    return max(lo, min(hi, x))\n",
        "\n",
        "def norm(s):\n",
        "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip().lower()\n",
        "\n",
        "def sim(a, b):\n",
        "    if not a or not b:\n",
        "        return 0.0\n",
        "    return float(fuzz.partial_ratio(norm(a), norm(b))) / 100.0  # 0~1\n",
        "\n",
        "def score_from_audit(cv_text, name_guess, loc_guess, audit_log):\n",
        "    \"\"\"\n",
        "    Final scoring (soft penalties, no hard cap):\n",
        "    - Base score\n",
        "    - Evidence coverage (LinkedIn heavy weight +0.4)\n",
        "    - Reduced conflict penalties (location/job)\n",
        "    - Very light company penalty\n",
        "    - Light CV support checks\n",
        "    - Extra compound penalty if BOTH location & job conflicts happen\n",
        "    \"\"\"\n",
        "\n",
        "    li = find_first(audit_log, \"get_linkedin_profile\")\n",
        "    fb = find_first(audit_log, \"get_facebook_profile\")\n",
        "\n",
        "    found_li = isinstance(li, dict) and not li.get(\"error\")\n",
        "    found_fb = isinstance(fb, dict) and not fb.get(\"error\")\n",
        "\n",
        "    # --------------------------\n",
        "    # 0) Base score\n",
        "    # --------------------------\n",
        "    score = 0.50\n",
        "    issues = []\n",
        "\n",
        "    # --------------------------\n",
        "    # 1) Evidence coverage bonus\n",
        "    # --------------------------\n",
        "    if found_li:\n",
        "        score += 0.40\n",
        "    else:\n",
        "        score -= 0.15\n",
        "        issues.append(\"linkedin_missing\")\n",
        "\n",
        "    if found_fb:\n",
        "        score += 0.10\n",
        "    else:\n",
        "        score -= 0.05\n",
        "        issues.append(\"facebook_missing\")\n",
        "\n",
        "    # --------------------------\n",
        "    # 2) Cross-platform consistency (soft)\n",
        "    # --------------------------\n",
        "    severe_loc_conflict = False\n",
        "    severe_job_conflict = False\n",
        "\n",
        "    if found_li and found_fb:\n",
        "        li_loc = f\"{li.get('city','')} {li.get('country','')}\".strip()\n",
        "        fb_loc = f\"{fb.get('city','')} {fb.get('country','')}\".strip()\n",
        "\n",
        "        li_job = (li.get(\"headline\") or \"\").strip()\n",
        "        li_ind = (li.get(\"industry\") or \"\").strip()\n",
        "\n",
        "        fb_job = (fb.get(\"current_job\") or \"\").strip()\n",
        "        fb_co  = (fb.get(\"current_company\") or \"\").strip()\n",
        "\n",
        "        # (2.1) location conflict (reduced penalty)\n",
        "        if li_loc and fb_loc and sim(li_loc, fb_loc) < 0.45:\n",
        "            score -= 0.12\n",
        "            issues.append(\"li_fb_location_conflict\")\n",
        "            severe_loc_conflict = True\n",
        "\n",
        "        # (2.2) job/industry conflict (reduced penalty)\n",
        "        job_ok = (sim(li_job, fb_job) >= 0.45) or (sim(li_ind, fb_job) >= 0.45)\n",
        "        if li_job and fb_job and not job_ok:\n",
        "            score -= 0.15\n",
        "            issues.append(\"li_fb_job_conflict\")\n",
        "            severe_job_conflict = True\n",
        "\n",
        "        # (2.3) company weak support (very light)\n",
        "        if fb_co and li_job and sim(fb_co, li_job) < 0.30:\n",
        "            score -= 0.02\n",
        "            issues.append(\"company_not_supported\")\n",
        "\n",
        "        # (2.4) compound penalty (NO CAP, just extra penalty)\n",
        "        if severe_loc_conflict and severe_job_conflict:\n",
        "            score -= 0.12\n",
        "            issues.append(\"compound_conflict_penalty\")\n",
        "\n",
        "    # --------------------------\n",
        "    # 3) CV text support (light)\n",
        "    # --------------------------\n",
        "    if found_li and cv_text:\n",
        "        t = norm(cv_text)\n",
        "        headline = norm(li.get(\"headline\"))\n",
        "        industry = norm(li.get(\"industry\"))\n",
        "\n",
        "        if headline and fuzz.partial_ratio(headline, t) < 60:\n",
        "            score -= 0.05\n",
        "            issues.append(\"li_headline_not_in_cv\")\n",
        "\n",
        "        if industry and fuzz.partial_ratio(industry, t) < 60:\n",
        "            score -= 0.03\n",
        "            issues.append(\"li_industry_not_in_cv\")\n",
        "\n",
        "    # --------------------------\n",
        "    # 4) Clamp + epsilon fix\n",
        "    # --------------------------\n",
        "    score = clamp(score)\n",
        "\n",
        "    # é¿å…æµ®ç‚¹åˆšå¥½å¡åœ¨ 0.5 é™„è¿‘\n",
        "    if abs(score - 0.5) < 1e-6:\n",
        "        score += 1e-4\n",
        "\n",
        "    return score, issues"
      ],
      "metadata": {
        "id": "3llcq8F56wW2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "scores = []\n",
        "\n",
        "for cv in all_cvs:\n",
        "    r = await run_agent_for_cv(cv, max_iters=8)\n",
        "    s, issues = score_from_audit(cv[\"text\"], r[\"name_guess\"], r[\"location_guess\"], r[\"audit_log\"])\n",
        "    r[\"score\"] = s\n",
        "    r[\"issues\"] = issues\n",
        "    results.append(r)\n",
        "    scores.append(s)\n",
        "\n",
        "print(\"âœ… scores =\", scores)\n",
        "assert len(scores) == 5\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX0IH-Te60Hw",
        "outputId": "0e42336e-4030-4583-b530-54a2481d7254"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… scores = [0.88, 1.0, 0.44999999999999996, 0.58, 0.59]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.88, 1.0, 0.44999999999999996, 0.58, 0.59]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for r in results:\n",
        "    print(\"=\"*60)\n",
        "    print(\"CV:\", r[\"file\"])\n",
        "    print(\"Score:\", round(r[\"score\"], 3))\n",
        "    print(\"Issues:\", r[\"issues\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD17H09bNPjk",
        "outputId": "af19d522-84f5-4c43-9d3e-bc3f03508857"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CV: CV_1.pdf\n",
            "Score: 0.88\n",
            "Issues: ['li_fb_location_conflict']\n",
            "============================================================\n",
            "CV: CV_2.pdf\n",
            "Score: 1.0\n",
            "Issues: []\n",
            "============================================================\n",
            "CV: CV_3.pdf\n",
            "Score: 0.45\n",
            "Issues: ['linkedin_missing']\n",
            "============================================================\n",
            "CV: CV_4.pdf\n",
            "Score: 0.58\n",
            "Issues: ['li_fb_location_conflict', 'li_fb_job_conflict', 'compound_conflict_penalty', 'li_industry_not_in_cv']\n",
            "============================================================\n",
            "CV: CV_5.pdf\n",
            "Score: 0.59\n",
            "Issues: ['li_fb_location_conflict', 'li_fb_job_conflict', 'company_not_supported', 'compound_conflict_penalty']\n"
          ]
        }
      ]
    }
  ]
}