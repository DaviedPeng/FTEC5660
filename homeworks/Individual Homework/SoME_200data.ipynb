{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78a85feec83543869635eba76d630c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1b86230deb14402b4b536b309533313",
              "IPY_MODEL_76530d27e0694060a8b813284b975516",
              "IPY_MODEL_d49b55f960c24f6a8c864bcd58aeed89"
            ],
            "layout": "IPY_MODEL_d6065b659d2443deb2a6b171e142fad7"
          }
        },
        "f1b86230deb14402b4b536b309533313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41298af9316b49f1bdffd5d4716abd04",
            "placeholder": "​",
            "style": "IPY_MODEL_a790cae66c534a31aab5215f598d76f6",
            "value": "database/post_data/all_posts.json: 100%"
          }
        },
        "76530d27e0694060a8b813284b975516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92ec151c04844a08e1b07ab7e77f212",
            "max": 303023188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54d21b6eb91b4b699f2788e4a7fb656d",
            "value": 303023188
          }
        },
        "d49b55f960c24f6a8c864bcd58aeed89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6800bff77763458aa66f8a02bb66c936",
            "placeholder": "​",
            "style": "IPY_MODEL_21171e9bc7df4037a0d7a4be47c26847",
            "value": " 303M/303M [00:05&lt;00:00, 188MB/s]"
          }
        },
        "d6065b659d2443deb2a6b171e142fad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41298af9316b49f1bdffd5d4716abd04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a790cae66c534a31aab5215f598d76f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b92ec151c04844a08e1b07ab7e77f212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d21b6eb91b4b699f2788e4a7fb656d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6800bff77763458aa66f8a02bb66c936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21171e9bc7df4037a0d7a4be47c26847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqxdc5JWOsOD",
        "outputId": "c483cf3d-a7e6-4af6-8223-b993c49fd45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/460.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m450.6/460.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.6/460.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install openai==1.61.0 tqdm huggingface_hub scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, random, time\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_DIR = Path(\"/content/ubp_project_clean\")\n",
        "DATA_DIR = PROJECT_DIR / \"data\"\n",
        "OUT_DIR = PROJECT_DIR / \"outputs\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 读取 GEMINI_API_KEY：优先环境变量，其次 Colab Secrets\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "if not GEMINI_API_KEY:\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "    except Exception:\n",
        "        GEMINI_API_KEY = None\n",
        "\n",
        "assert GEMINI_API_KEY, \"❌ GEMINI_API_KEY 没读到：请在 Colab Secrets 里设置 GEMINI_API_KEY 并重启 runtime\"\n",
        "\n",
        "print(\"✅ Project:\", PROJECT_DIR)\n",
        "print(\"✅ GEMINI_API_KEY loaded:\", bool(GEMINI_API_KEY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWWxTYULO8ll",
        "outputId": "2eaf6ae1-c17e-4af1-c890-d8b59e134e7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Project: /content/ubp_project_clean\n",
            "✅ GEMINI_API_KEY loaded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/LivXue/SoMe.git /content/SoMe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jE0yqb1O-p5",
        "outputId": "bb434055-f946-45a0-bfba-16de4ca61f36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/SoMe'...\n",
            "remote: Enumerating objects: 205, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 205 (delta 51), reused 193 (delta 48), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (205/205), 9.96 MiB | 9.59 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt_path = \"/content/SoMe/datasets/user_behavior_prediction/ground_truth.json\"\n",
        "print(\"exists:\", os.path.exists(gt_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z00vwzM6PWtN",
        "outputId": "75c84270-c1e3-48d5-e644-2779d5fd3e03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "post_path = hf_hub_download(\n",
        "    repo_id=\"LivXue/SoMe\",\n",
        "    repo_type=\"dataset\",\n",
        "    filename=\"database/post_data/all_posts.json\"\n",
        ")\n",
        "\n",
        "print(\"all_posts path:\", post_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "78a85feec83543869635eba76d630c76",
            "f1b86230deb14402b4b536b309533313",
            "76530d27e0694060a8b813284b975516",
            "d49b55f960c24f6a8c864bcd58aeed89",
            "d6065b659d2443deb2a6b171e142fad7",
            "41298af9316b49f1bdffd5d4716abd04",
            "a790cae66c534a31aab5215f598d76f6",
            "b92ec151c04844a08e1b07ab7e77f212",
            "54d21b6eb91b4b699f2788e4a7fb656d",
            "6800bff77763458aa66f8a02bb66c936",
            "21171e9bc7df4037a0d7a4be47c26847"
          ]
        },
        "id": "5qE10bQiPXes",
        "outputId": "90c8859e-6375-45d8-b62f-bcec35ef0377"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "database/post_data/all_posts.json:   0%|          | 0.00/303M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78a85feec83543869635eba76d630c76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_posts path: /root/.cache/huggingface/hub/datasets--LivXue--SoMe/snapshots/33c8a1c48b01edd8c7be7fab0a29f6e1ad2181e0/database/post_data/all_posts.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "\n",
        "GT_PATH = \"/content/SoMe/datasets/user_behavior_prediction/ground_truth.json\"\n",
        "POST_PATH = \"/root/.cache/huggingface/hub/datasets--LivXue--SoMe/snapshots\"\n",
        "\n",
        "# 找到all_posts.json真实路径\n",
        "def find_all_posts(base):\n",
        "    for root, dirs, files in os.walk(base):\n",
        "        for f in files:\n",
        "            if f == \"all_posts.json\":\n",
        "                return os.path.join(root, f)\n",
        "\n",
        "POST_PATH = find_all_posts(POST_PATH)\n",
        "\n",
        "print(\"GT:\", GT_PATH)\n",
        "print(\"POST:\", POST_PATH)\n",
        "\n",
        "gt = json.load(open(GT_PATH,\"r\",encoding=\"utf-8\"))\n",
        "posts = json.load(open(POST_PATH,\"r\",encoding=\"utf-8\"))\n",
        "\n",
        "print(\"users:\",len(gt[\"like\"]))\n",
        "print(\"posts:\",len(posts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiE8i42HPZga",
        "outputId": "0bdcd706-7924-49c4-f1a1-bda81afc257c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GT: /content/SoMe/datasets/user_behavior_prediction/ground_truth.json\n",
            "POST: /root/.cache/huggingface/hub/datasets--LivXue--SoMe/snapshots/33c8a1c48b01edd8c7be7fab0a29f6e1ad2181e0/database/post_data/all_posts.json\n",
            "users: 500\n",
            "posts: 833609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = []\n",
        "\n",
        "for uid, d in gt[\"like\"].items():\n",
        "\n",
        "    for idx, item in enumerate(d):\n",
        "\n",
        "        wid = item[\"weibo_id\"]\n",
        "        label = item[\"label\"]\n",
        "\n",
        "        if wid in posts:\n",
        "\n",
        "            samples.append(\n",
        "                (\n",
        "                    uid,\n",
        "                    idx,\n",
        "                    wid,\n",
        "                    label,\n",
        "                    posts[wid]\n",
        "                )\n",
        "            )\n",
        "\n",
        "samples200 = samples[:200]\n",
        "\n",
        "print(\"samples:\",len(samples200))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZjeT3R5PzQz",
        "outputId": "1f5012fb-d7da-4577-b19e-12c4f17034b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# 读取 GEMINI_API_KEY：优先环境变量，其次 Colab Secrets\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "if not GEMINI_API_KEY:\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "    except Exception:\n",
        "        GEMINI_API_KEY = None\n",
        "\n",
        "assert GEMINI_API_KEY, \"❌ GEMINI_API_KEY 没读到：请在 Colab Secrets 里设置 GEMINI_API_KEY 并重启 runtime\"\n",
        "\n",
        "BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "MODEL_NAME = \"gemini-3-flash-preview\"\n",
        "\n",
        "client = OpenAI(api_key=GEMINI_API_KEY, base_url=BASE_URL)\n",
        "\n",
        "print(\"✅ GEMINI key loaded:\", bool(GEMINI_API_KEY))\n",
        "print(\"✅ model:\", MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITxPd1TtQqzE",
        "outputId": "bd5133b7-447c-480e-ef21-fd31f4331b78"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GEMINI key loaded: True\n",
            "✅ model: gemini-3-flash-preview\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import signal\n",
        "import time\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "def _timeout_handler(signum, frame):\n",
        "    raise TimeoutException()\n",
        "\n",
        "signal.signal(signal.SIGALRM, _timeout_handler)\n",
        "\n",
        "def ask_llm(prompt, timeout_sec=45, max_retries=3):\n",
        "    last_err = None\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "            r = client.chat.completions.create(\n",
        "                model=MODEL_NAME,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0,\n",
        "                timeout=timeout_sec\n",
        "            )\n",
        "\n",
        "            return r.choices[0].message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            err = str(e)\n",
        "            last_err = err\n",
        "\n",
        "            retryable = any(k in err for k in [\n",
        "                \"Timeout\", \"ReadTimeout\", \"ConnectTimeout\",\n",
        "                \"429\", \"Rate limit\", \"503\", \"502\", \"500\"\n",
        "            ])\n",
        "\n",
        "            if retryable and attempt < max_retries:\n",
        "                sleep_s = min(2 ** attempt, 8)\n",
        "                print(\"Retry after error:\", err)\n",
        "                time.sleep(sleep_s)\n",
        "                continue\n",
        "\n",
        "            if \"Timeout\" in err:\n",
        "                return \"TIMEOUT\"\n",
        "\n",
        "            return \"ERROR: \" + err\n",
        "\n",
        "    return \"ERROR: \" + str(last_err)\n",
        "\n",
        "def parse_yesno(text: str):\n",
        "    t = (text or \"\").strip()\n",
        "    if \"是\" in t and \"否\" not in t:\n",
        "        return \"是\"\n",
        "    if \"否\" in t and \"是\" not in t:\n",
        "        return \"否\"\n",
        "    # 若两者都出现：取最后出现的那个\n",
        "    last_is = t.rfind(\"是\")\n",
        "    last_no = t.rfind(\"否\")\n",
        "    if last_is == -1 and last_no == -1:\n",
        "        return None\n",
        "    return \"是\" if last_is > last_no else \"否\"\n",
        "\n",
        "def get_post_text(post: dict) -> str:\n",
        "    return str(post.get(\"内容\", \"\")).strip()"
      ],
      "metadata": {
        "id": "lf_-Hun6QsS4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def norm_label(x):\n",
        "    s = str(x).strip()\n",
        "    s = s.strip('\"').strip(\"'\").strip()\n",
        "    return s  # \"是\"/\"否\"\n",
        "\n",
        "def build_user_history(uid: str, target_wid: str, k=5):\n",
        "    \"\"\"\n",
        "    从 ground_truth like 中取该用户 label=是 的历史微博（排除 target）\n",
        "    返回 list[str]（微博文本）\n",
        "    \"\"\"\n",
        "    items = gt[\"like\"].get(uid, [])\n",
        "    liked_wids = []\n",
        "    for it in items:\n",
        "        wid = str(it.get(\"weibo_id\"))\n",
        "        if wid == target_wid:\n",
        "            continue\n",
        "        if norm_label(it.get(\"label\")) == \"是\" and wid in posts:\n",
        "            liked_wids.append(wid)\n",
        "    liked_wids = liked_wids[:k]\n",
        "    return [get_post_text(posts[w]) for w in liked_wids]\n",
        "\n",
        "def retrieve_similar_from_history(target_text: str, history_texts: list[str], topm=3):\n",
        "    if not history_texts:\n",
        "        return []\n",
        "    corpus = history_texts + [target_text]\n",
        "    vec = TfidfVectorizer(max_features=2000)\n",
        "    X = vec.fit_transform(corpus)\n",
        "    sims = cosine_similarity(X[-1], X[:-1]).flatten()\n",
        "    idxs = sims.argsort()[::-1][:topm]\n",
        "    return [history_texts[i] for i in idxs]\n",
        "\n",
        "def prompt_baseline(post_text: str) -> str:\n",
        "    return f\"\"\"你是社交媒体行为预测助手。\n",
        "任务：判断“某用户”是否会对这条微博点赞。\n",
        "\n",
        "微博内容：\n",
        "{post_text}\n",
        "\n",
        "只输出一个字：是 或 否\n",
        "\"\"\"\n",
        "\n",
        "def prompt_history(post_text: str, history_texts: list[str]) -> str:\n",
        "    history_block = \"\\n\".join([f\"- {t}\" for t in history_texts]) if history_texts else \"(无)\"\n",
        "    return f\"\"\"你是社交媒体行为预测助手。\n",
        "你会看到该用户“曾经点赞过的微博内容”（少量），请基于历史偏好预测他是否会点赞目标微博。\n",
        "\n",
        "用户历史点赞内容：\n",
        "{history_block}\n",
        "\n",
        "目标微博内容：\n",
        "{post_text}\n",
        "\n",
        "只输出一个字：是 或 否\n",
        "\"\"\"\n",
        "\n",
        "def prompt_retrieval(post_text: str, retrieved_texts: list[str]) -> str:\n",
        "    retrieved_block = \"\\n\".join([f\"- {t}\" for t in retrieved_texts]) if retrieved_texts else \"(无)\"\n",
        "    return f\"\"\"你是社交媒体行为预测助手。\n",
        "已从该用户历史点赞内容中检索出与目标微博最相近的几条作为证据，请基于证据判断他是否会点赞目标微博。\n",
        "\n",
        "检索到的相似历史点赞微博：\n",
        "{retrieved_block}\n",
        "\n",
        "目标微博内容：\n",
        "{post_text}\n",
        "\n",
        "只输出一个字：是 或 否\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "u3I6OxuRQx2k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "OUT_DIR = Path(\"/content/ubp_project_clean/outputs\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def run_method(method_name: str, samples, out_json_path: Path,\n",
        "               k_history=5, topm=3, timeout_sec=60, save_every=10):\n",
        "    \"\"\"\n",
        "    保存格式：\n",
        "    {\n",
        "      \"点赞\": {\n",
        "        uid: { idx: \"是/否/TIMEOUT/ERROR:xxx/UNPARSED\" }\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    results = {\"点赞\": {}}\n",
        "\n",
        "    # 断点续跑\n",
        "    if out_json_path.exists():\n",
        "        try:\n",
        "            results = json.load(open(out_json_path, \"r\", encoding=\"utf-8\"))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    for uid, idx, wid, label, post in tqdm(samples, desc=method_name):\n",
        "        uid = str(uid); idx = str(idx); wid = str(wid)\n",
        "        results[\"点赞\"].setdefault(uid, {})\n",
        "\n",
        "        if idx in results[\"点赞\"][uid]:\n",
        "            continue\n",
        "\n",
        "        post_text = get_post_text(post)\n",
        "\n",
        "        if method_name == \"baseline\":\n",
        "            prompt = prompt_baseline(post_text)\n",
        "\n",
        "        elif method_name == \"history\":\n",
        "            hist = build_user_history(uid, wid, k=k_history)\n",
        "            prompt = prompt_history(post_text, hist)\n",
        "\n",
        "        elif method_name == \"retrieval_text\":\n",
        "            hist = build_user_history(uid, wid, k=k_history)\n",
        "            retrieved = retrieve_similar_from_history(post_text, hist, topm=topm)\n",
        "            prompt = prompt_retrieval(post_text, retrieved)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"unknown method\")\n",
        "\n",
        "        raw = ask_llm(prompt, timeout_sec=timeout_sec)\n",
        "        yn = parse_yesno(raw)\n",
        "\n",
        "        if yn is None:\n",
        "            if raw.startswith(\"TIMEOUT\") or raw.startswith(\"ERROR\"):\n",
        "                pred = raw\n",
        "            else:\n",
        "                pred = \"UNPARSED\"\n",
        "        else:\n",
        "            pred = yn\n",
        "\n",
        "        results[\"点赞\"][uid][idx] = pred\n",
        "\n",
        "        # 定期保存\n",
        "        count_preds = sum(len(v) for v in results[\"点赞\"].values())\n",
        "        if count_preds % save_every == 0:\n",
        "            with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # 最后强制保存\n",
        "    with open(out_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return results\n",
        "\n",
        "def evaluate(results, samples):\n",
        "    gold = {(str(uid), str(idx)): norm_label(label) for uid, idx, wid, label, post in samples}\n",
        "\n",
        "    total = 0\n",
        "    parsed = 0\n",
        "    correct = 0\n",
        "    unparsed = 0\n",
        "    error_like = 0\n",
        "\n",
        "    for (uid, idx), lab in gold.items():\n",
        "        total += 1\n",
        "        pred = results.get(\"点赞\", {}).get(uid, {}).get(idx, None)\n",
        "\n",
        "        if pred in [\"是\", \"否\"]:\n",
        "            parsed += 1\n",
        "            if pred == lab:\n",
        "                correct += 1\n",
        "        else:\n",
        "            unparsed += 1\n",
        "            if isinstance(pred, str) and (pred.startswith(\"ERROR\") or pred.startswith(\"TIMEOUT\")):\n",
        "                error_like += 1\n",
        "\n",
        "    tcr = parsed / total if total else 0\n",
        "    acc_known = correct / parsed if parsed else 0\n",
        "    return {\"Total\": total, \"TCR\": tcr, \"ACC_known\": acc_known, \"Unparsed\": unparsed, \"Error_like\": error_like}"
      ],
      "metadata": {
        "id": "NU58ckfIQ1IL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = samples200[:5]\n",
        "\n",
        "for m in [\"baseline\", \"history\", \"retrieval_text\"]:\n",
        "    outp = OUT_DIR / f\"{MODEL_NAME}_{m}_n5.json\"\n",
        "    print(\"\\n=== Running\", m, \"on 5 samples ===\")\n",
        "    res = run_method(m, test_samples, outp, k_history=5, topm=3, timeout_sec=60, save_every=2)\n",
        "    print(\"Saved:\", outp)\n",
        "    print(\"Eval:\", evaluate(res, test_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiD2Ec33Q7R8",
        "outputId": "8a41d7f8-ab95-4987-f6b8-4f96b4a2a48b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Running baseline on 5 samples ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "baseline: 100%|██████████| 5/5 [00:24<00:00,  4.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/ubp_project_clean/outputs/gemini-3-flash-preview_baseline_n5.json\n",
            "Eval: {'Total': 5, 'TCR': 1.0, 'ACC_known': 0.6, 'Unparsed': 0, 'Error_like': 0}\n",
            "\n",
            "=== Running history on 5 samples ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "history: 100%|██████████| 5/5 [00:19<00:00,  3.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/ubp_project_clean/outputs/gemini-3-flash-preview_history_n5.json\n",
            "Eval: {'Total': 5, 'TCR': 1.0, 'ACC_known': 0.8, 'Unparsed': 0, 'Error_like': 0}\n",
            "\n",
            "=== Running retrieval_text on 5 samples ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "retrieval_text: 100%|██████████| 5/5 [00:22<00:00,  4.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/ubp_project_clean/outputs/gemini-3-flash-preview_retrieval_text_n5.json\n",
            "Eval: {'Total': 5, 'TCR': 1.0, 'ACC_known': 0.4, 'Unparsed': 0, 'Error_like': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_reports = {}\n",
        "\n",
        "for m in [\"baseline\", \"history\", \"retrieval_text\"]:\n",
        "    outp = OUT_DIR / f\"{MODEL_NAME}_{m}_n200.json\"\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"✅ Running\", m, \"on 200 samples\")\n",
        "    res = run_method(m, samples200, outp, k_history=5, topm=3, timeout_sec=60, save_every=10)\n",
        "    rep = evaluate(res, samples200)\n",
        "    final_reports[m] = rep\n",
        "    print(\"Saved:\", outp)\n",
        "    print(\"Report:\", rep)\n",
        "\n",
        "print(\"\\n✅ All done. Summary:\")\n",
        "print(json.dumps(final_reports, ensure_ascii=False, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "A1M_dg1yRf1A",
        "outputId": "912c175d-40ca-4a7a-aeb1-d75edda4d7d0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "✅ Running baseline on 200 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "baseline: 100%|██████████| 200/200 [00:00<00:00, 280087.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/ubp_project_clean/outputs/gemini-3-flash-preview_baseline_n200.json\n",
            "Report: {'Total': 200, 'TCR': 0.995, 'ACC_known': 0.45226130653266333, 'Unparsed': 1, 'Error_like': 1}\n",
            "\n",
            "==============================\n",
            "✅ Running history on 200 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "history:   1%|          | 2/200 [00:09<15:18,  4.64s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-702/2437776169.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n==============================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Running\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on 200 samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfinal_reports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-702/958384298.py\u001b[0m in \u001b[0;36mrun_method\u001b[0;34m(method_name, samples, out_json_path, k_history, topm, timeout_sec, save_every)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown method\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0myn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_yesno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-702/3793458190.py\u001b[0m in \u001b[0;36mask_llm\u001b[0;34m(prompt, timeout_sec, max_retries)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_retries\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             r = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    997\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = run_method(\"baseline\", samples200, outp, timeout_sec=45)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOnEaxecWTe8",
        "outputId": "19656dde-66d7-499a-f2d5-4984802c9762"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "baseline: 100%|██████████| 200/200 [07:16<00:00,  2.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outp = OUT_DIR / f\"{MODEL_NAME}_history_n200.json\"\n",
        "\n",
        "res = run_method(\n",
        "    \"history\",\n",
        "    samples200,\n",
        "    outp,\n",
        "    k_history=5,\n",
        "    timeout_sec=45\n",
        ")\n",
        "\n",
        "print(evaluate(res, samples200))"
      ],
      "metadata": {
        "id": "XhxvgzDtG-BD",
        "outputId": "fa4cad21-cbdb-41a6-ce94-1078f0df4051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "history: 100%|██████████| 200/200 [13:46<00:00,  4.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Total': 200, 'TCR': 1.0, 'ACC_known': 0.4, 'Unparsed': 0, 'Error_like': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outp = OUT_DIR / f\"{MODEL_NAME}_retrieval_text_n200.json\"\n",
        "\n",
        "res = run_method(\n",
        "    \"retrieval_text\",\n",
        "    samples200,\n",
        "    outp,\n",
        "    k_history=5,\n",
        "    topm=3,\n",
        "    timeout_sec=45\n",
        ")\n",
        "\n",
        "print(evaluate(res, samples200))"
      ],
      "metadata": {
        "id": "amg9kzWCGV66",
        "outputId": "252e1c6c-baea-436c-df9d-265b5c353f54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "retrieval_text: 100%|██████████| 200/200 [12:46<00:00,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Total': 200, 'TCR': 1.0, 'ACC_known': 0.32, 'Unparsed': 0, 'Error_like': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# ========= 1. 正确的 ground truth 路径 =========\n",
        "gt_path = \"/content/SoMe/datasets/user_behavior_prediction/ground_truth.json\"\n",
        "\n",
        "# ========= 2. 结果文件路径 =========\n",
        "base_dir = \"/content/ubp_project_clean/outputs\"\n",
        "\n",
        "baseline_path   = os.path.join(base_dir, \"gemini-3-flash-preview_baseline_n200.json\")\n",
        "history_path    = os.path.join(base_dir, \"gemini-3-flash-preview_history_n200.json\")\n",
        "retrieval_path  = os.path.join(base_dir, \"gemini-3-flash-preview_retrieval_text_n200.json\")\n",
        "\n",
        "# ========= 3. 读取数据 =========\n",
        "gt = json.load(open(gt_path))\n",
        "\n",
        "baseline_pred = json.load(open(baseline_path))\n",
        "history_pred = json.load(open(history_path))\n",
        "retrieval_pred = json.load(open(retrieval_path))\n",
        "\n",
        "# ========= 4. 构建 GT map =========\n",
        "gt_map = {}\n",
        "\n",
        "for uid, arr in gt[\"like\"].items():\n",
        "    for idx, item in enumerate(arr):\n",
        "        gt_map[(uid, str(idx))] = item[\"label\"]\n",
        "\n",
        "# ========= 5. 计算 ACC =========\n",
        "def calc_acc(pred):\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for uid, d in pred[\"点赞\"].items():\n",
        "        for idx, ans in d.items():\n",
        "\n",
        "            key = (uid, idx)\n",
        "\n",
        "            if key not in gt_map:\n",
        "                continue\n",
        "\n",
        "            gt_label = gt_map[key]\n",
        "\n",
        "            if ans in [\"是\", \"否\"]:\n",
        "                total += 1\n",
        "                if ans == gt_label:\n",
        "                    correct += 1\n",
        "\n",
        "    if total == 0:\n",
        "        return 0\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "acc_baseline = calc_acc(baseline_pred)\n",
        "acc_history = calc_acc(history_pred)\n",
        "acc_retrieval = calc_acc(retrieval_pred)\n",
        "\n",
        "# ========= 6. 打印结果 =========\n",
        "print(\"========== FINAL RESULT ==========\")\n",
        "print(f\"Baseline ACC      : {acc_baseline:.5f}\")\n",
        "print(f\"History ACC       : {acc_history:.5f}\")\n",
        "print(f\"Retrieval ACC     : {acc_retrieval:.5f}\")"
      ],
      "metadata": {
        "id": "sKdVRNsvPlHp",
        "outputId": "8eadafb1-51f9-469d-a183-ffc6bfe55c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== FINAL RESULT ==========\n",
            "Baseline ACC      : 0.45226\n",
            "History ACC       : 0.40000\n",
            "Retrieval ACC     : 0.32000\n"
          ]
        }
      ]
    }
  ]
}